{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk.data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt # plot figures\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "import os, time, random, re, codecs, spacy, math, torch, spacy, transformers, nltk\n",
    "from os.path import join\n",
    "import seaborn as sns # plot figures\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ipywidgets import IntProgress\n",
    "from sklearn.metrics import classification_report\n",
    "from transformers import AutoModel, BertTokenizerFast\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.decomposition import PCA\n",
    "import tensorflow as tf\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer \n",
    "from sklearn import metrics\n",
    "import transformers\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertTokenizer, BertModel, BertConfig\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import tensorflow as tf\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from bert_sklearn import BertClassifier\n",
    "from bert_sklearn import BertRegressor\n",
    "from bert_sklearn import load_model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from transformers import AdamW\n",
    "import torch.optim as optim\n",
    "import codecs, json, copy\n",
    "from tqdm import tqdm\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from transformers.models.bert.modeling_bert import BertModel,BertForMaskedLM, BertForSequenceClassification\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "import copy\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '....csv'\n",
    "df = pd.read_csv(path)\n",
    "df = df.drop(df.columns[0], axis=1)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_2 = '....csv'\n",
    "df_2 = pd.read_csv(path_2)\n",
    "df_2 = df_2.drop(df_2.columns[0], axis=1)\n",
    "# df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seeding:\n",
    "def seed_all(seed):  \n",
    "    ''' A function to seed everything for getting stable results and reproducibility'''\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "seed = 2021    \n",
    "seed_all(seed)\n",
    "# Testing size:\n",
    "sizeoftest = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(447, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['end', 'file_key', 'label', 'start', 'str']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns.tolist()) # column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "end          int64\n",
       "file_key     int64\n",
       "label        int64\n",
       "start        int64\n",
       "str         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "end         False\n",
       "file_key    False\n",
       "label       False\n",
       "start       False\n",
       "str         False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    356\n",
       "0     91\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.countplot(y=\"label\", data=df)\n",
    "plt.title('Distribution of  class (MEH data)')\n",
    "plt.xlabel('Number of class')\n",
    "total = len(df['label'])\n",
    "for p in ax.patches:\n",
    "        percentage = '{:.1f}%'.format(100 * p.get_width()/total)\n",
    "        x = p.get_x() + p.get_width() + 0.02\n",
    "        y = p.get_y() + p.get_height()/2\n",
    "        ax.annotate(percentage, (x, y))\n",
    "# plt.savefig('class_label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 267\n",
      "Dev size: 90\n",
      "Test size: 90\n"
     ]
    }
   ],
   "source": [
    "texts = df['str'].tolist()\n",
    "labels = df['label'].tolist()\n",
    "X, X_test, y, y_test = train_test_split(texts,\n",
    "                                        labels,\n",
    "                                        test_size=0.2,\n",
    "                                        train_size=0.8,\n",
    "                                        random_state=seed)\n",
    "X_train, X_dev, y_train, y_dev = train_test_split(X,\n",
    "                                                  y,\n",
    "                                                  test_size=0.25,\n",
    "                                                  train_size=0.75,\n",
    "                                                  random_state=seed)\n",
    "# len(X_train), len(y_train), len(X_test), len(y_test), len(X_dev), len(y_dev)\n",
    "print(\"Train size:\", len(X_train))\n",
    "print(\"Dev size:\", len(X_dev))\n",
    "print(\"Test size:\", len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT model\n",
    "## Initial training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# import BERT-base pretrained model\n",
    "bert = AutoModel.from_pretrained('bert-base-uncased')\n",
    "# Load the BERT tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_X_y(texts, labels):    \n",
    "    tokenized = tokenizer.batch_encode_plus(\n",
    "        texts,\n",
    "        padding=True,\n",
    "        truncation=True\n",
    "    )\n",
    "    seq = torch.tensor(tokenized['input_ids'])\n",
    "    mask = torch.tensor(tokenized['attention_mask'])\n",
    "    y = torch.tensor(labels)\n",
    "    return seq, mask, y\n",
    "\n",
    "train_seq, train_mask, train_y = prepare_X_y(X_train, y_train)\n",
    "dev_seq, dev_mask, dev_y = prepare_X_y(X_dev, y_dev)\n",
    "test_seq, test_mask, test_y = prepare_X_y(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a batch size\n",
    "batch_size = 5\n",
    "epochs = 20\n",
    "learning_rate = 1e-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrap tensors\n",
    "training_data = TensorDataset(train_seq, train_mask, train_y)\n",
    "dev_data = TensorDataset(dev_seq, dev_mask, dev_y)\n",
    "# testing_data = TensorDataset(test_seq, test_mask, test_y)\n",
    "\n",
    "# sampler for sampling the data during training\n",
    "sampler = RandomSampler(training_data)\n",
    "\n",
    "# dataLoader\n",
    "training_data_loader = DataLoader(training_data, sampler=sampler, batch_size=batch_size)\n",
    "dev_data_loader = DataLoader(dev_data, batch_size=batch_size) \n",
    "# testing_data_loader = DataLoader(testing_data, sampler=sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "\n",
    "class BERT_Text_Classifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, bert, class_num, bert_dim=768, hidden_dim=512):\n",
    "      \n",
    "        super(BERT_Text_Classifier, self).__init__()\n",
    "\n",
    "        self.bert = bert \n",
    "\n",
    "        # define a dropout\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "        # use relu\n",
    "        self.relu =  nn.ReLU()\n",
    "\n",
    "        # feedforward layer\n",
    "        self.fc1 = nn.Linear(bert_dim, hidden_dim)\n",
    "\n",
    "        # Output layer\n",
    "        self.fc2 = nn.Linear(hidden_dim, class_num)\n",
    "\n",
    "        #softmax function instance\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    #define the forward pass\n",
    "    def forward(self, seq, mask):\n",
    "\n",
    "        # use pretrained bert to read the sequence with the mask (pay attention to which tokens)\n",
    "        bert_out = self.bert(seq, attention_mask=mask)\n",
    "        \n",
    "        # print('last_hidden_state', bert_out['last_hidden_state'].size(), \n",
    "        #      'pooler_output', bert_out['pooler_output'].size())\n",
    "        \n",
    "        lhs = bert_out['pooler_output']\n",
    "        x = self.fc1(lhs)        \n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        # apply softmax activation\n",
    "        x = self.softmax(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(m, evl_loader, eval_labels=[1]):\n",
    "    from sklearn.metrics import precision_recall_fscore_support\n",
    "    preds = []\n",
    "    lbls = []\n",
    "    print('evaluating...', flush=True)\n",
    "    for step, batch in enumerate(tqdm(evl_loader)):        \n",
    "        # use gpu if available\n",
    "        batch = [r.to(device) for r in batch]\n",
    "        seq, mask, labels = batch\n",
    "        with torch.no_grad():\n",
    "            batch_result = m(seq, mask)\n",
    "            rets = np.argmax(batch_result.detach().cpu(), axis = 1).tolist()\n",
    "            preds += rets\n",
    "            lbls += labels.tolist()\n",
    "    p, r, f, _ = precision_recall_fscore_support(lbls, preds, labels=eval_labels)\n",
    "    return {'precision': p[0], 'recall': r[0], 'f1': f[0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to train the model\n",
    "def train():\n",
    "    # dropout activates when in train mode \n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0\n",
    "    for step, batch in enumerate(tqdm(training_data_loader)):\n",
    "        \n",
    "        # use gpu if available\n",
    "        batch = [r.to(device) for r in batch]\n",
    "        \n",
    "        seq, mask, labels = batch\n",
    "        \n",
    "        # reset gradients \n",
    "        model.zero_grad()        \n",
    "\n",
    "        # get model outputs\n",
    "        outputs = model.forward(seq, mask)\n",
    "\n",
    "        # compute the loss between actual and predicted values\n",
    "        loss = cross_entropy(outputs, labels)\n",
    "\n",
    "        # accumulate loss\n",
    "        total_loss = total_loss + loss.item()\n",
    "\n",
    "        # calculate the gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # deal with the exploding gradient problem\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "    # calculate average loss\n",
    "    average_loss = total_loss / len(training_data_loader)\n",
    "    \n",
    "    ret = evaluate(model, dev_data_loader)\n",
    "  \n",
    "    return average_loss, ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = {'control': 0, 'case': 1}\n",
    "# initialise the model use pretrained bert instance and the label numbers\n",
    "model = BERT_Text_Classifier(bert, class_num=len(categories))\n",
    "\n",
    "# push the model to GPU\n",
    "model = model.to(device)\n",
    "\n",
    "# define the optimizer\n",
    "# optimizer = AdamW(model.parameters(),\n",
    "#                   lr = learning_rate)\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "cross_entropy  = nn.NLLLoss() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:01<00:00, 29.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 111.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.372 dev performance, p:0.918, r:0.985, f1:0.950\n",
      "current best score is 0.950\n",
      "\n",
      " Epoch 2 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 30.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 110.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.280 dev performance, p:0.918, r:0.985, f1:0.950\n",
      "\n",
      " Epoch 3 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 30.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 110.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.291 dev performance, p:0.919, r:1.000, f1:0.958\n",
      "current best score is 0.958\n",
      "\n",
      " Epoch 4 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 30.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 110.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.284 dev performance, p:0.931, r:0.985, f1:0.957\n",
      "\n",
      " Epoch 5 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 30.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 112.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.260 dev performance, p:0.918, r:0.985, f1:0.950\n",
      "\n",
      " Epoch 6 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 29.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 89.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.232 dev performance, p:0.918, r:0.985, f1:0.950\n",
      "\n",
      " Epoch 7 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 29.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 113.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.222 dev performance, p:0.919, r:1.000, f1:0.958\n",
      "\n",
      " Epoch 8 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 30.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 112.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.195 dev performance, p:0.918, r:0.985, f1:0.950\n",
      "\n",
      " Epoch 9 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 30.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 111.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.222 dev performance, p:0.918, r:0.985, f1:0.950\n",
      "\n",
      " Epoch 10 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 29.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 112.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.175 dev performance, p:0.926, r:0.926, f1:0.926\n",
      "\n",
      " Epoch 11 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 30.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 112.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.220 dev performance, p:0.918, r:0.985, f1:0.950\n",
      "\n",
      " Epoch 12 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 30.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 102.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.197 dev performance, p:0.918, r:0.985, f1:0.950\n",
      "\n",
      " Epoch 13 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 30.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 101.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.201 dev performance, p:0.917, r:0.971, f1:0.943\n",
      "\n",
      " Epoch 14 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 30.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 101.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.184 dev performance, p:0.925, r:0.912, f1:0.919\n",
      "\n",
      " Epoch 15 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 30.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 108.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.175 dev performance, p:0.918, r:0.985, f1:0.950\n",
      "\n",
      " Epoch 16 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 30.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 101.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.213 dev performance, p:0.918, r:0.985, f1:0.950\n",
      "\n",
      " Epoch 17 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 30.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 102.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.215 dev performance, p:0.918, r:0.985, f1:0.950\n",
      "\n",
      " Epoch 18 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 30.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 107.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.203 dev performance, p:0.918, r:0.985, f1:0.950\n",
      "\n",
      " Epoch 19 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 30.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 112.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.212 dev performance, p:0.918, r:0.985, f1:0.950\n",
      "\n",
      " Epoch 20 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 30.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 111.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.157 dev performance, p:0.984, r:0.912, f1:0.947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#for each epoch\n",
    "\n",
    "best_model_state = None\n",
    "best_score = -1\n",
    "\n",
    "for epoch in range(epochs):\n",
    "     \n",
    "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs), flush=True)\n",
    "    #train model\n",
    "    train_loss, performance = train()\n",
    "    print('\\nTraining Loss: {:.3f}'.format(train_loss), \n",
    "          'dev performance, p:{precision:.3f}, r:{recall:.3f}, f1:{f1:.3f}'.format(**performance), flush=True)\n",
    "    if best_score < performance['f1']:\n",
    "        best_score = performance['f1']\n",
    "        best_model_state = copy.deepcopy(model.state_dict())\n",
    "        print('current best score is {0:.3f}'.format(best_score), flush=True)    \n",
    "\n",
    "ran = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = 'MEH_bert_initial.pt'\n",
    "torch.save(best_model_state, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not ran:\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    model_file = 'MEH_bert_initial.pt'\n",
    "\n",
    "    categories = {'control': 0, 'case': 1}\n",
    "    # initialise the model use pretrained bert instance and the label numbers\n",
    "    model = BERT_Text_Classifier(bert, class_num=len(categories))\n",
    "\n",
    "    model.load_state_dict(torch.load(model_file))\n",
    "    model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seq = test_seq.to(device)\n",
    "test_mask = test_mask.to(device)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:00<00:00, 110.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': 0.9722222222222222, 'recall': 0.9333333333333333, 'f1': 0.9523809523809524}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# dataLoader for test set\n",
    "# wrap tensors\n",
    "testing_data = TensorDataset(test_seq, test_mask, test_y)\n",
    "testing_data_loader = DataLoader(testing_data, batch_size=batch_size)     \n",
    "print(evaluate(model, testing_data_loader))\n",
    "# preds = np.argmax(preds.detach().cpu(), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.80      0.75        15\n",
      "           1       0.96      0.93      0.95        75\n",
      "\n",
      "    accuracy                           0.91        90\n",
      "   macro avg       0.83      0.87      0.85        90\n",
      "weighted avg       0.92      0.91      0.91        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predicting, so gradients\n",
    "with torch.no_grad():\n",
    "    preds = model(test_seq, test_mask)\n",
    "    \n",
    "preds = np.argmax(preds.detach().cpu(), axis = 1)\n",
    "print(classification_report(test_y, preds))\n",
    "# report_BERT1 = classification_report(test_y, preds)\n",
    "# classification_report_csv(report_BERT1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_bert = confusion_matrix(test_y, preds, labels=[1,0])\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cm_bert, annot=True, ax = ax, cmap='Blues', fmt=\"d\")\n",
    "\n",
    "ax.set_title('Confusion Matrix of BERT (MEH data)')\n",
    "\n",
    "ax.set_xlabel('Predicted Labels')\n",
    "ax.set_ylabel('True Labels')\n",
    "\n",
    "ax.xaxis.set_ticklabels(['FAKE', 'REAL'])\n",
    "ax.yaxis.set_ticklabels(['FAKE', 'REAL'])\n",
    "plt.savefig('Confusion_matrix_bert_meh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building sklearn text classifier...\n",
      "Building sklearn text classifier...\n",
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "Building sklearn text classifier...\n",
      "Loading bert-base-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 178, validation data size: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.62it/s, loss=0.893]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.65it/s, loss=0.482]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.68it/s, loss=0.323]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.68it/s, loss=0.217]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.56it/s, loss=0.203]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.64it/s, loss=0.171]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.67it/s, loss=0.201]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.61it/s, loss=0.169] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.67it/s, loss=0.184]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.66it/s, loss=0.188] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.55it/s, loss=0.194]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.67it/s, loss=0.155] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.68it/s, loss=0.129] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.69it/s, loss=0.143]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.69it/s, loss=0.136] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.54it/s, loss=0.131] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.64it/s, loss=0.101] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.65it/s, loss=0.105] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.60it/s, loss=0.0978]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.68it/s, loss=0.0995]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.64it/s, loss=0.0886]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.53it/s, loss=0.0749]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.68it/s, loss=0.0791]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.66it/s, loss=0.0688]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.66it/s, loss=0.0741] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.69it/s, loss=0.0651]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.69it/s, loss=0.0733]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.63it/s, loss=0.133] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.69it/s, loss=0.102] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.66it/s, loss=0.104]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.65it/s, loss=0.0886]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.66it/s, loss=0.0794]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.62it/s, loss=0.0789]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.52it/s, loss=0.1]   \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.54it/s, loss=0.086] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.69it/s, loss=0.0995]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.52it/s, loss=0.0807]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.67it/s, loss=0.0705]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.62it/s, loss=0.0566]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.67it/s, loss=0.0711]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.60it/s, loss=0.0616]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.61it/s, loss=0.0664]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.70it/s, loss=0.0634]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.54it/s, loss=0.0651]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.61it/s, loss=0.0633]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.67it/s, loss=0.0683]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.52it/s, loss=0.0616]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.58it/s, loss=0.0704] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.53it/s, loss=0.0719]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.68it/s, loss=0.0589]\n",
      "Predicting: 100%|██████████| 12/12 [00:00<00:00, 16.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building sklearn text classifier...\n",
      "Loading bert-base-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 178, validation data size: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.61it/s, loss=0.895]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.64it/s, loss=0.502]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.61it/s, loss=0.298]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.61it/s, loss=0.234]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.62it/s, loss=0.252]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.61it/s, loss=0.198] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.60it/s, loss=0.258]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.62it/s, loss=0.206] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.59it/s, loss=0.173]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.49it/s, loss=0.165]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.62it/s, loss=0.169]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.62it/s, loss=0.138] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.62it/s, loss=0.151]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.60it/s, loss=0.154] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.48it/s, loss=0.148] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.56it/s, loss=0.148] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.56it/s, loss=0.15]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.49it/s, loss=0.141] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.58it/s, loss=0.133]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.56it/s, loss=0.146] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.61it/s, loss=0.144] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.62it/s, loss=0.131] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.62it/s, loss=0.12] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.60it/s, loss=0.131] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.62it/s, loss=0.118] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.60it/s, loss=0.127] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.60it/s, loss=0.123] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.59it/s, loss=0.111]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.59it/s, loss=0.118]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.62it/s, loss=0.115] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.61it/s, loss=0.12]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.55it/s, loss=0.115] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.56it/s, loss=0.106]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.49it/s, loss=0.117] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.53it/s, loss=0.109] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.64it/s, loss=0.13] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.51it/s, loss=0.119] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.43it/s, loss=0.113] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.57it/s, loss=0.118] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.53it/s, loss=0.11] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.61it/s, loss=0.117] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.52it/s, loss=0.115]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.60it/s, loss=0.103]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.55it/s, loss=0.104]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.47it/s, loss=0.115]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.48it/s, loss=0.1]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.61it/s, loss=0.11]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.58it/s, loss=0.0992]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.60it/s, loss=0.124]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.61it/s, loss=0.109] \n",
      "Predicting: 100%|██████████| 12/12 [00:00<00:00, 15.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building sklearn text classifier...\n",
      "Loading bert-base-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 178, validation data size: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.55it/s, loss=0.902]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.52it/s, loss=0.513]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.53it/s, loss=0.34] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.54it/s, loss=0.252]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.57it/s, loss=0.28] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.55it/s, loss=0.207] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.44it/s, loss=0.218]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.53it/s, loss=0.235] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.57it/s, loss=0.181]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.56it/s, loss=0.211]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.49it/s, loss=0.18] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.56it/s, loss=0.162]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.45it/s, loss=0.16] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.56it/s, loss=0.152] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.53it/s, loss=0.154] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.57it/s, loss=0.149] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.57it/s, loss=0.143] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.59it/s, loss=0.125] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.54it/s, loss=0.116]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.47it/s, loss=0.108] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.58it/s, loss=0.142]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.61it/s, loss=0.108] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.57it/s, loss=0.116]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.52it/s, loss=0.129] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.50it/s, loss=0.11] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.43it/s, loss=0.122] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.58it/s, loss=0.114] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.51it/s, loss=0.116] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.57it/s, loss=0.12] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.59it/s, loss=0.119] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.52it/s, loss=0.113] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.42it/s, loss=0.113] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.59it/s, loss=0.112]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.47it/s, loss=0.111] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.48it/s, loss=0.106]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.59it/s, loss=0.11]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.53it/s, loss=0.118]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.50it/s, loss=0.121] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.46it/s, loss=0.109] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.52it/s, loss=0.111]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.57it/s, loss=0.123] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.58it/s, loss=0.113]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.43it/s, loss=0.106]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.45it/s, loss=0.113]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.59it/s, loss=0.105]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.58it/s, loss=0.105] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.58it/s, loss=0.107] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.52it/s, loss=0.0971]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.57it/s, loss=0.101] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.46it/s, loss=0.106]\n",
      "Predicting: 100%|██████████| 12/12 [00:00<00:00, 14.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building sklearn text classifier...\n",
      "Loading bert-base-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 178, validation data size: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.44it/s, loss=0.86] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.57it/s, loss=0.416]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.56it/s, loss=0.306]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.52it/s, loss=0.22] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.60it/s, loss=0.216]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.58it/s, loss=0.233]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.55it/s, loss=0.194]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.54it/s, loss=0.174]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.57it/s, loss=0.177]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.58it/s, loss=0.134] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.50it/s, loss=0.16] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.57it/s, loss=0.133] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.58it/s, loss=0.0865]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.58it/s, loss=0.0737]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.55it/s, loss=0.0813]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.57it/s, loss=0.0709]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.57it/s, loss=0.0707]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.50it/s, loss=0.09]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.55it/s, loss=0.0605]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.42it/s, loss=0.0958]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.48it/s, loss=0.0722]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.45it/s, loss=0.067] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.50it/s, loss=0.0743]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.43it/s, loss=0.0627]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.56it/s, loss=0.0658] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.58it/s, loss=0.0624]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.46it/s, loss=0.0729]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.45it/s, loss=0.0639]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.57it/s, loss=0.0685] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.52it/s, loss=0.0588]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.59it/s, loss=0.0638]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.59it/s, loss=0.0646]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.58it/s, loss=0.0571]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.55it/s, loss=0.0762]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.56it/s, loss=0.0679]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.51it/s, loss=0.0803]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.50it/s, loss=0.0693]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.57it/s, loss=0.0671]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.44it/s, loss=0.0558]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.56it/s, loss=0.0641]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.53it/s, loss=0.0571]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.58it/s, loss=0.0612]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.56it/s, loss=0.061] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.52it/s, loss=0.0599]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.56it/s, loss=0.0645]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.57it/s, loss=0.0612]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.57it/s, loss=0.0558]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.55it/s, loss=0.062]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.58it/s, loss=0.0685]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.57it/s, loss=0.0583]\n",
      "Predicting: 100%|██████████| 12/12 [00:00<00:00, 14.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building sklearn text classifier...\n",
      "Loading bert-base-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 178, validation data size: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.52it/s, loss=0.865]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.50it/s, loss=0.427]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.52it/s, loss=0.284]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.51it/s, loss=0.247]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.52it/s, loss=0.283]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.39it/s, loss=0.301]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.49it/s, loss=0.247]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.41it/s, loss=0.208] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.52it/s, loss=0.171]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.50it/s, loss=0.169]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.42it/s, loss=0.198]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.46it/s, loss=0.151] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.51it/s, loss=0.171]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.50it/s, loss=0.162] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.51it/s, loss=0.175]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.40it/s, loss=0.153]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.53it/s, loss=0.227]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.50it/s, loss=0.148] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.48it/s, loss=0.124] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.51it/s, loss=0.147] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.47it/s, loss=0.138] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.43it/s, loss=0.124] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.54it/s, loss=0.127]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.52it/s, loss=0.135] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.52it/s, loss=0.124] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.52it/s, loss=0.127] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.51it/s, loss=0.125] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.52it/s, loss=0.111]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.48it/s, loss=0.115] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.51it/s, loss=0.107]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.49it/s, loss=0.123] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.56it/s, loss=0.105] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.57it/s, loss=0.102]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.49it/s, loss=0.116]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.57it/s, loss=0.105]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.55it/s, loss=0.121] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.56it/s, loss=0.119] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.58it/s, loss=0.109] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.58it/s, loss=0.109] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.58it/s, loss=0.104] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.52it/s, loss=0.117] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.42it/s, loss=0.111]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.44it/s, loss=0.103]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.53it/s, loss=0.103]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.54it/s, loss=0.114] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.54it/s, loss=0.098]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.55it/s, loss=0.101] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.47it/s, loss=0.0987]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.55it/s, loss=0.131] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.59it/s, loss=0.113] \n",
      "Predicting: 100%|██████████| 12/12 [00:00<00:00, 14.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building sklearn text classifier...\n",
      "Loading bert-base-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 178, validation data size: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.49it/s, loss=0.875]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.50it/s, loss=0.447]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.47it/s, loss=0.302]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.53it/s, loss=0.258]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.48it/s, loss=0.463]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.54it/s, loss=0.256]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.53it/s, loss=0.196]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.51it/s, loss=0.214] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.44it/s, loss=0.161]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.50it/s, loss=0.172]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.49it/s, loss=0.129]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.51it/s, loss=0.186]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.47it/s, loss=0.172] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.51it/s, loss=0.161] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.51it/s, loss=0.159] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.42it/s, loss=0.15] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.52it/s, loss=0.17] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.49it/s, loss=0.127] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.44it/s, loss=0.134]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.47it/s, loss=0.124] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.41it/s, loss=0.147] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.50it/s, loss=0.125] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.53it/s, loss=0.132]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.49it/s, loss=0.138]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.41it/s, loss=0.125]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.42it/s, loss=0.131] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.52it/s, loss=0.119] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.41it/s, loss=0.132]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.53it/s, loss=0.124] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.51it/s, loss=0.128] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.53it/s, loss=0.139] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.45it/s, loss=0.127] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.39it/s, loss=0.124]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.53it/s, loss=0.133] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.52it/s, loss=0.119]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.52it/s, loss=0.121]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.44it/s, loss=0.128]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.43it/s, loss=0.128] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.52it/s, loss=0.119] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.51it/s, loss=0.122]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.44it/s, loss=0.14]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.48it/s, loss=0.124]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.52it/s, loss=0.118]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.51it/s, loss=0.122]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.52it/s, loss=0.124]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.52it/s, loss=0.117] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.49it/s, loss=0.12] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.47it/s, loss=0.119]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.40it/s, loss=0.118] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.52it/s, loss=0.12] \n",
      "Predicting: 100%|██████████| 12/12 [00:00<00:00, 14.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building sklearn text classifier...\n",
      "Loading bert-base-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 178, validation data size: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.47it/s, loss=0.924]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.37it/s, loss=0.608]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.54it/s, loss=0.367]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.51it/s, loss=0.288]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.51it/s, loss=0.221]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.47it/s, loss=0.246]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.54it/s, loss=0.209]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.50it/s, loss=0.178]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.50it/s, loss=0.183]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.50it/s, loss=0.165] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.39it/s, loss=0.189]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.41it/s, loss=0.165] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.46it/s, loss=0.183] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.50it/s, loss=0.152] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.52it/s, loss=0.164]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.50it/s, loss=0.155]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.51it/s, loss=0.14] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.49it/s, loss=0.125] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.38it/s, loss=0.11] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.49it/s, loss=0.112] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.50it/s, loss=0.081] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.52it/s, loss=0.0825]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.47it/s, loss=0.0859]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.43it/s, loss=0.0796]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.36it/s, loss=0.0752]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.51it/s, loss=0.0637]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.51it/s, loss=0.0785]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.45it/s, loss=0.0736]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.53it/s, loss=0.0724]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.47it/s, loss=0.0647]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.52it/s, loss=0.066] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.38it/s, loss=0.0834]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.53it/s, loss=0.0608]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.39it/s, loss=0.0829]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.49it/s, loss=0.0702]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.45it/s, loss=0.0812]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.49it/s, loss=0.0817]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.50it/s, loss=0.0726]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.51it/s, loss=0.0648]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.52it/s, loss=0.0688]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.48it/s, loss=0.0654]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.49it/s, loss=0.0665]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.48it/s, loss=0.0663]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.54it/s, loss=0.0685]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.49it/s, loss=0.0669]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.48it/s, loss=0.0671]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.48it/s, loss=0.0589]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.44it/s, loss=0.0633] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.46it/s, loss=0.0772]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.41it/s, loss=0.0635]\n",
      "Predicting: 100%|██████████| 12/12 [00:00<00:00, 13.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building sklearn text classifier...\n",
      "Loading bert-base-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 178, validation data size: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.45it/s, loss=0.923]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.51it/s, loss=0.609]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.38it/s, loss=0.354]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.43it/s, loss=0.264]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.52it/s, loss=0.234]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.40it/s, loss=0.21]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.52it/s, loss=0.247]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.47it/s, loss=0.215]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.49it/s, loss=0.204]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.49it/s, loss=0.242]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.51it/s, loss=0.233]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.52it/s, loss=0.188]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.50it/s, loss=0.238]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.44it/s, loss=0.234] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.51it/s, loss=0.209]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.40it/s, loss=0.202]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.46it/s, loss=0.194] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.51it/s, loss=0.166] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.38it/s, loss=0.152]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.49it/s, loss=0.164] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.53it/s, loss=0.143] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.50it/s, loss=0.136] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.37it/s, loss=0.129]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.41it/s, loss=0.132]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.44it/s, loss=0.119]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.50it/s, loss=0.126] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.45it/s, loss=0.118]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.47it/s, loss=0.116]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.52it/s, loss=0.126]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.53it/s, loss=0.114] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.50it/s, loss=0.116] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.49it/s, loss=0.112]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.49it/s, loss=0.101]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.52it/s, loss=0.117] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.49it/s, loss=0.109]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.47it/s, loss=0.132]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.42it/s, loss=0.118] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.47it/s, loss=0.107] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.51it/s, loss=0.123] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.39it/s, loss=0.117]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.49it/s, loss=0.114] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.42it/s, loss=0.113]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.43it/s, loss=0.1]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.37it/s, loss=0.105]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.54it/s, loss=0.114] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.51it/s, loss=0.0962]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.48it/s, loss=0.108] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.51it/s, loss=0.105]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.54it/s, loss=0.109] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.45it/s, loss=0.108] \n",
      "Predicting: 100%|██████████| 12/12 [00:00<00:00, 13.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building sklearn text classifier...\n",
      "Loading bert-base-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 178, validation data size: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.48it/s, loss=0.929]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.41it/s, loss=0.631]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.51it/s, loss=0.4]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.36it/s, loss=0.295]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.41it/s, loss=0.258]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.35it/s, loss=0.228] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.51it/s, loss=0.235]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.48it/s, loss=0.253]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.46it/s, loss=0.213]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.42it/s, loss=0.221]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.43it/s, loss=0.215]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.41it/s, loss=0.223]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.49it/s, loss=0.217]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.35it/s, loss=0.232]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.43it/s, loss=0.221]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.42it/s, loss=0.218]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.40it/s, loss=0.228]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.47it/s, loss=0.192]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.48it/s, loss=0.188]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.47it/s, loss=0.162] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.44it/s, loss=0.191]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.41it/s, loss=0.149]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.50it/s, loss=0.151]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.46it/s, loss=0.144]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.50it/s, loss=0.152]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.44it/s, loss=0.169] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.42it/s, loss=0.128] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.46it/s, loss=0.131] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.49it/s, loss=0.131]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.49it/s, loss=0.133] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.51it/s, loss=0.113] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.37it/s, loss=0.112] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.42it/s, loss=0.111]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.49it/s, loss=0.108] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.47it/s, loss=0.113]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.44it/s, loss=0.111]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.45it/s, loss=0.112] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.47it/s, loss=0.123] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.47it/s, loss=0.117] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.48it/s, loss=0.122]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.48it/s, loss=0.12]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.47it/s, loss=0.128] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.47it/s, loss=0.105]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.48it/s, loss=0.109]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.47it/s, loss=0.111]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.46it/s, loss=0.111] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.43it/s, loss=0.111]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.48it/s, loss=0.111]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.44it/s, loss=0.115] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.48it/s, loss=0.114]\n",
      "Predicting: 100%|██████████| 12/12 [00:00<00:00, 13.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building sklearn text classifier...\n",
      "Loading bert-base-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 178, validation data size: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.39it/s, loss=0.913]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.43it/s, loss=0.547]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.32it/s, loss=0.346]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.38it/s, loss=0.267]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.43it/s, loss=0.205]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.31it/s, loss=0.191]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.37it/s, loss=0.202]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.44it/s, loss=0.196]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.42it/s, loss=0.177]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.36it/s, loss=0.166] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.41it/s, loss=0.19] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.44it/s, loss=0.159] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.45it/s, loss=0.171] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.40it/s, loss=0.138] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.29it/s, loss=0.134]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.43it/s, loss=0.126] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.45it/s, loss=0.0933]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.34it/s, loss=0.106] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.40it/s, loss=0.0662]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.38it/s, loss=0.0888]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.45it/s, loss=0.0676]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.40it/s, loss=0.0644]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.43it/s, loss=0.0702]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.45it/s, loss=0.0797]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.38it/s, loss=0.0734] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.41it/s, loss=0.0662]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.32it/s, loss=0.0789]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.41it/s, loss=0.0677]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.44it/s, loss=0.0694]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.37it/s, loss=0.0639]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.39it/s, loss=0.0704]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.41it/s, loss=0.0701]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.46it/s, loss=0.0614]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.44it/s, loss=0.0935]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.43it/s, loss=0.071] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.31it/s, loss=0.0937]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.46it/s, loss=0.0731]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.43it/s, loss=0.0714] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.43it/s, loss=0.0622]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.33it/s, loss=0.0682]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.39it/s, loss=0.0649]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.46it/s, loss=0.0638]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.45it/s, loss=0.0616]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.43it/s, loss=0.069] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.46it/s, loss=0.0632]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.45it/s, loss=0.0669]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.43it/s, loss=0.0623]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.37it/s, loss=0.0664] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.43it/s, loss=0.0755]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.47it/s, loss=0.0572]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.38it/s, loss=0.0863]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.47it/s, loss=0.0625]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.34it/s, loss=0.0622]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.47it/s, loss=0.0675]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.43it/s, loss=0.0598]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.42it/s, loss=0.0584]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.46it/s, loss=0.0812]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.42it/s, loss=0.0696]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.33it/s, loss=0.0625]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.37it/s, loss=0.0598]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.30it/s, loss=0.0598]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.42it/s, loss=0.0642]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.41it/s, loss=0.0561]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.45it/s, loss=0.067] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.44it/s, loss=0.0635]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.46it/s, loss=0.0654]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.45it/s, loss=0.0627]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.44it/s, loss=0.061]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.38it/s, loss=0.075] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.45it/s, loss=0.0637]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.47it/s, loss=0.064]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.45it/s, loss=0.0632]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.47it/s, loss=0.0543]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.46it/s, loss=0.0637] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.41it/s, loss=0.0568]\n",
      "Predicting: 100%|██████████| 12/12 [00:00<00:00, 13.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building sklearn text classifier...\n",
      "Loading bert-base-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 178, validation data size: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.34it/s, loss=0.913]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.41it/s, loss=0.566]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.40it/s, loss=0.335]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.34it/s, loss=0.251]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.39it/s, loss=0.27] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.33it/s, loss=0.239] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.41it/s, loss=0.265]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.40it/s, loss=0.232]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.41it/s, loss=0.235]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.29it/s, loss=0.221]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.28it/s, loss=0.218]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.40it/s, loss=0.182]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.41it/s, loss=0.176]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.34it/s, loss=0.178] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.40it/s, loss=0.159] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.33it/s, loss=0.155] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.31it/s, loss=0.165] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.41it/s, loss=0.142] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.42it/s, loss=0.125]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.29it/s, loss=0.122] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.27it/s, loss=0.119] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.41it/s, loss=0.111] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.37it/s, loss=0.118]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.42it/s, loss=0.115] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.25it/s, loss=0.105] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.28it/s, loss=0.116] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.41it/s, loss=0.118] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.41it/s, loss=0.106]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.39it/s, loss=0.116]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.30it/s, loss=0.118] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.42it/s, loss=0.11]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.39it/s, loss=0.106] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.40it/s, loss=0.0992]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.36it/s, loss=0.112] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.32it/s, loss=0.105]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.39it/s, loss=0.122] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.32it/s, loss=0.114] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.33it/s, loss=0.107] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.33it/s, loss=0.103] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.43it/s, loss=0.105] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.31it/s, loss=0.109] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.26it/s, loss=0.11]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.43it/s, loss=0.0985]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.42it/s, loss=0.105]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.34it/s, loss=0.114] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.37it/s, loss=0.0959]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.28it/s, loss=0.102] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.39it/s, loss=0.0979]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.36it/s, loss=0.112] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.39it/s, loss=0.101] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.39it/s, loss=0.115] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.41it/s, loss=0.111] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.42it/s, loss=0.108]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.39it/s, loss=0.12]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.33it/s, loss=0.108] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.37it/s, loss=0.11] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.32it/s, loss=0.123] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.37it/s, loss=0.112]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.37it/s, loss=0.113] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.38it/s, loss=0.106]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.34it/s, loss=0.101]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.35it/s, loss=0.102]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.42it/s, loss=0.101] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.30it/s, loss=0.105] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.40it/s, loss=0.115] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.34it/s, loss=0.104] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.40it/s, loss=0.0966]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.40it/s, loss=0.0991]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.29it/s, loss=0.115] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.31it/s, loss=0.0971]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.40it/s, loss=0.113] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.36it/s, loss=0.108] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.27it/s, loss=0.122] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.35it/s, loss=0.0999]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.29it/s, loss=0.108]\n",
      "Predicting: 100%|██████████| 12/12 [00:00<00:00, 12.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building sklearn text classifier...\n",
      "Loading bert-base-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 178, validation data size: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.33it/s, loss=0.92] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.33it/s, loss=0.581]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.34it/s, loss=0.383]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.26it/s, loss=0.278]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.32it/s, loss=0.254]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.35it/s, loss=0.233] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.31it/s, loss=0.233]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.25it/s, loss=0.216]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.24it/s, loss=0.161]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.37it/s, loss=0.164] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.33it/s, loss=0.16] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.35it/s, loss=0.137]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.24it/s, loss=0.172]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.37it/s, loss=0.222]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.37it/s, loss=0.195] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.38it/s, loss=0.191]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.35it/s, loss=0.191]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.35it/s, loss=0.164]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.34it/s, loss=0.136]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.35it/s, loss=0.125] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.37it/s, loss=0.151] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.35it/s, loss=0.127] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.31it/s, loss=0.131] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.37it/s, loss=0.141] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.37it/s, loss=0.115] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.35it/s, loss=0.133] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.26it/s, loss=0.12]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.34it/s, loss=0.115]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.33it/s, loss=0.124] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.31it/s, loss=0.12]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.28it/s, loss=0.113] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.35it/s, loss=0.116] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.35it/s, loss=0.114]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.34it/s, loss=0.107]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.34it/s, loss=0.115]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.28it/s, loss=0.119]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.29it/s, loss=0.117] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.25it/s, loss=0.112] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.27it/s, loss=0.12]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.38it/s, loss=0.109]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.35it/s, loss=0.115] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.32it/s, loss=0.112] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.27it/s, loss=0.103]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.27it/s, loss=0.11] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.30it/s, loss=0.111]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.38it/s, loss=0.103] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.33it/s, loss=0.101] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.24it/s, loss=0.11] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.32it/s, loss=0.105] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.38it/s, loss=0.108]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.33it/s, loss=0.104] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.33it/s, loss=0.118] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.35it/s, loss=0.107] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.36it/s, loss=0.123]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.34it/s, loss=0.113] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.30it/s, loss=0.119] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.37it/s, loss=0.113] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.36it/s, loss=0.103] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.34it/s, loss=0.112] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.33it/s, loss=0.112]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.28it/s, loss=0.107]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.36it/s, loss=0.108]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.37it/s, loss=0.098] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.38it/s, loss=0.109] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.39it/s, loss=0.112] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.24it/s, loss=0.103] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.38it/s, loss=0.0968]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.38it/s, loss=0.102] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.31it/s, loss=0.119] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.36it/s, loss=0.0989]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.35it/s, loss=0.114] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.38it/s, loss=0.112] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.37it/s, loss=0.128] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.30it/s, loss=0.106]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.36it/s, loss=0.102]\n",
      "Predicting: 100%|██████████| 12/12 [00:01<00:00, 11.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building sklearn text classifier...\n",
      "Loading bert-base-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 178, validation data size: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.29it/s, loss=0.893]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.38it/s, loss=0.482]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.35it/s, loss=0.323]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.24it/s, loss=0.217]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.25it/s, loss=0.203]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.26it/s, loss=0.171]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.32it/s, loss=0.215]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.36it/s, loss=0.16]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.36it/s, loss=0.202]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.35it/s, loss=0.187] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.38it/s, loss=0.203]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.37it/s, loss=0.147] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.37it/s, loss=0.136] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.32it/s, loss=0.103] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.36it/s, loss=0.111]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.30it/s, loss=0.086] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.40it/s, loss=0.0763]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.38it/s, loss=0.0938]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.34it/s, loss=0.0736]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.27it/s, loss=0.107] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.27it/s, loss=0.107] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.30it/s, loss=0.0804]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.37it/s, loss=0.0799]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.34it/s, loss=0.0702]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.35it/s, loss=0.0755] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.38it/s, loss=0.0703]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.37it/s, loss=0.0864]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.26it/s, loss=0.0648]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.37it/s, loss=0.0716] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.37it/s, loss=0.0614]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.26it/s, loss=0.0695]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.36it/s, loss=0.0638]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.27it/s, loss=0.0594]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.34it/s, loss=0.088] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.34it/s, loss=0.0679]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.36it/s, loss=0.0836]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.37it/s, loss=0.0723]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.34it/s, loss=0.0659]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.39it/s, loss=0.0604]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.37it/s, loss=0.0658]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.37it/s, loss=0.0613]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.28it/s, loss=0.0634]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.35it/s, loss=0.0574]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.36it/s, loss=0.0613]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.37it/s, loss=0.0653]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.34it/s, loss=0.0633]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.32it/s, loss=0.059] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.27it/s, loss=0.0595] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.35it/s, loss=0.0688]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.36it/s, loss=0.058] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.26it/s, loss=0.0832]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.33it/s, loss=0.0649]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.33it/s, loss=0.061] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.36it/s, loss=0.0755]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.30it/s, loss=0.0581]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.37it/s, loss=0.0571]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.38it/s, loss=0.0778]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.35it/s, loss=0.0639]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.38it/s, loss=0.0639]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.37it/s, loss=0.0575]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.26it/s, loss=0.0621]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.32it/s, loss=0.0606]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.34it/s, loss=0.0569]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.37it/s, loss=0.0645]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.33it/s, loss=0.0578]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.30it/s, loss=0.0565]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.39it/s, loss=0.0591]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.31it/s, loss=0.0543] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.26it/s, loss=0.0734]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.37it/s, loss=0.0591]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.34it/s, loss=0.0607]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.32it/s, loss=0.0635]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.33it/s, loss=0.0596]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.37it/s, loss=0.061]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.34it/s, loss=0.0598]\n",
      "Predicting: 100%|██████████| 12/12 [00:01<00:00, 11.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building sklearn text classifier...\n",
      "Loading bert-base-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 178, validation data size: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.36it/s, loss=0.895]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.38it/s, loss=0.502]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.37it/s, loss=0.298]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.37it/s, loss=0.234]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.37it/s, loss=0.252]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.35it/s, loss=0.198] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.38it/s, loss=0.265]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.34it/s, loss=0.205] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.37it/s, loss=0.183]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.39it/s, loss=0.187]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.35it/s, loss=0.191]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.34it/s, loss=0.161] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.37it/s, loss=0.167]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.35it/s, loss=0.162] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.38it/s, loss=0.159] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.37it/s, loss=0.149] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.37it/s, loss=0.148] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.37it/s, loss=0.135] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.38it/s, loss=0.129] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.36it/s, loss=0.147] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.39it/s, loss=0.13]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.34it/s, loss=0.132] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.40it/s, loss=0.115]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.37it/s, loss=0.128] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.39it/s, loss=0.116] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.37it/s, loss=0.123] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.34it/s, loss=0.122] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.32it/s, loss=0.105]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.27it/s, loss=0.107]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.36it/s, loss=0.112] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.32it/s, loss=0.12]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.36it/s, loss=0.11]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.34it/s, loss=0.107]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.35it/s, loss=0.112] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.34it/s, loss=0.105]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.34it/s, loss=0.122] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.39it/s, loss=0.125] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.37it/s, loss=0.113] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.37it/s, loss=0.114] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.38it/s, loss=0.112]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.33it/s, loss=0.124] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.34it/s, loss=0.121]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.41it/s, loss=0.111]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.30it/s, loss=0.108]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.39it/s, loss=0.125] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.36it/s, loss=0.0973]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.33it/s, loss=0.107] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.31it/s, loss=0.101]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.32it/s, loss=0.114] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.37it/s, loss=0.104] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.35it/s, loss=0.114] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.37it/s, loss=0.113] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.38it/s, loss=0.121]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.37it/s, loss=0.111] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.38it/s, loss=0.113] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.30it/s, loss=0.109]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.31it/s, loss=0.132] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.39it/s, loss=0.106] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.36it/s, loss=0.118] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.35it/s, loss=0.104]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.26it/s, loss=0.106]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.35it/s, loss=0.102]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.33it/s, loss=0.103] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.31it/s, loss=0.108] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.33it/s, loss=0.0971]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.34it/s, loss=0.103] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.24it/s, loss=0.0989]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.35it/s, loss=0.103]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.35it/s, loss=0.119] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.38it/s, loss=0.102]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.35it/s, loss=0.111] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.32it/s, loss=0.114]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.33it/s, loss=0.118] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.29it/s, loss=0.105] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.27it/s, loss=0.0964]\n",
      "Predicting: 100%|██████████| 12/12 [00:01<00:00, 11.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building sklearn text classifier...\n",
      "Loading bert-base-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 178, validation data size: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.36it/s, loss=0.902]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.31it/s, loss=0.513]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.35it/s, loss=0.34] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.38it/s, loss=0.252]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.37it/s, loss=0.28] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.35it/s, loss=0.208] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.35it/s, loss=0.223]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.36it/s, loss=0.235]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.37it/s, loss=0.158]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.36it/s, loss=0.16]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.35it/s, loss=0.138]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.36it/s, loss=0.127]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.28it/s, loss=0.178]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.30it/s, loss=0.159] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.32it/s, loss=0.151] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.34it/s, loss=0.176]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.26it/s, loss=0.154]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.34it/s, loss=0.129] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.33it/s, loss=0.117]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.36it/s, loss=0.114] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.34it/s, loss=0.146]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.33it/s, loss=0.116] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.34it/s, loss=0.117] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.35it/s, loss=0.132] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.30it/s, loss=0.118]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.38it/s, loss=0.118] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.25it/s, loss=0.113] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.34it/s, loss=0.125]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.35it/s, loss=0.119] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.33it/s, loss=0.123] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.31it/s, loss=0.115] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.39it/s, loss=0.118] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.28it/s, loss=0.11] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.33it/s, loss=0.11]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.31it/s, loss=0.116]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.31it/s, loss=0.118]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.28it/s, loss=0.108]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.29it/s, loss=0.12]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.37it/s, loss=0.11]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.26it/s, loss=0.116]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.39it/s, loss=0.122] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.36it/s, loss=0.109] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.31it/s, loss=0.105]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.33it/s, loss=0.111]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.33it/s, loss=0.104]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.34it/s, loss=0.104] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.31it/s, loss=0.105] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.32it/s, loss=0.0996]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.37it/s, loss=0.0998]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.38it/s, loss=0.108]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.31it/s, loss=0.105] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.36it/s, loss=0.128] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.31it/s, loss=0.109] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.37it/s, loss=0.118] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.27it/s, loss=0.111] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.32it/s, loss=0.113] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.39it/s, loss=0.114] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.25it/s, loss=0.109] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.35it/s, loss=0.112] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.32it/s, loss=0.113]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.37it/s, loss=0.108]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.35it/s, loss=0.108]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.34it/s, loss=0.101] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.34it/s, loss=0.104] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.38it/s, loss=0.112] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.35it/s, loss=0.107]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.36it/s, loss=0.102]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.35it/s, loss=0.101] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.33it/s, loss=0.115]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.35it/s, loss=0.0989]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.36it/s, loss=0.111] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.31it/s, loss=0.116] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.35it/s, loss=0.122] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.37it/s, loss=0.108] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.32it/s, loss=0.11]  \n",
      "Predicting: 100%|██████████| 12/12 [00:01<00:00, 11.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building sklearn text classifier...\n",
      "Loading bert-base-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 178, validation data size: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.31it/s, loss=0.936]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.33it/s, loss=0.686]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.25it/s, loss=0.412]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.32it/s, loss=0.315]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.30it/s, loss=0.254]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.31it/s, loss=0.24] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.31it/s, loss=0.21] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.30it/s, loss=0.212]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.32it/s, loss=0.226]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.31it/s, loss=0.22] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.32it/s, loss=0.218]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.30it/s, loss=0.193] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.26it/s, loss=0.201]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.32it/s, loss=0.177]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.28it/s, loss=0.184]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.28it/s, loss=0.178]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.31it/s, loss=0.154]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.32it/s, loss=0.174]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.33it/s, loss=0.158]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.25it/s, loss=0.164]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.32it/s, loss=0.119] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.33it/s, loss=0.116] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.32it/s, loss=0.0848]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.33it/s, loss=0.0902]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.32it/s, loss=0.0822]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.30it/s, loss=0.0828]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.30it/s, loss=0.0812]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.32it/s, loss=0.0733]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.32it/s, loss=0.0898] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.31it/s, loss=0.105] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.33it/s, loss=0.0879]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.31it/s, loss=0.0762]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.32it/s, loss=0.0726]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.28it/s, loss=0.095] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.31it/s, loss=0.0783]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.31it/s, loss=0.1]   \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.28it/s, loss=0.0797]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.35it/s, loss=0.082] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.27it/s, loss=0.066] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.25it/s, loss=0.0743]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.34it/s, loss=0.0764]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.31it/s, loss=0.0683]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.31it/s, loss=0.0675]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.30it/s, loss=0.0701]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.30it/s, loss=0.067] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.32it/s, loss=0.0684]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.31it/s, loss=0.0669]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.30it/s, loss=0.0649]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.30it/s, loss=0.0808]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.33it/s, loss=0.064] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.32it/s, loss=0.0828]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.31it/s, loss=0.0671]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.33it/s, loss=0.0637]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.32it/s, loss=0.07]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.24it/s, loss=0.0595]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.21it/s, loss=0.0605]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.31it/s, loss=0.0842]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.30it/s, loss=0.0772]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.32it/s, loss=0.0673]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.30it/s, loss=0.0635]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.24it/s, loss=0.0538]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.22it/s, loss=0.063] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.28it/s, loss=0.0639]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.31it/s, loss=0.0674]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.29it/s, loss=0.0703]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.16it/s, loss=0.0646]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.15it/s, loss=0.0713]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.26it/s, loss=0.0633] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.28it/s, loss=0.0865]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.24it/s, loss=0.0672]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.31it/s, loss=0.067]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.31it/s, loss=0.0735]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.30it/s, loss=0.0591]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.32it/s, loss=0.0688]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.34it/s, loss=0.0609]\n",
      "Predicting: 100%|██████████| 12/12 [00:01<00:00, 10.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building sklearn text classifier...\n",
      "Loading bert-base-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 178, validation data size: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.27it/s, loss=0.934]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.28it/s, loss=0.697]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.32it/s, loss=0.405]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.29it/s, loss=0.298]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.25it/s, loss=0.287]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.30it/s, loss=0.216]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.27it/s, loss=0.259]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.30it/s, loss=0.224]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.24it/s, loss=0.199]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.20it/s, loss=0.22] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.23it/s, loss=0.217]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.28it/s, loss=0.181]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.28it/s, loss=0.218]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.25it/s, loss=0.215] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.28it/s, loss=0.209]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.30it/s, loss=0.208]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.29it/s, loss=0.196] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.29it/s, loss=0.171] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.21it/s, loss=0.17] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.29it/s, loss=0.177] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.30it/s, loss=0.174]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.25it/s, loss=0.149]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.27it/s, loss=0.149]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.23it/s, loss=0.148]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.24it/s, loss=0.135]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.19it/s, loss=0.139] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.30it/s, loss=0.126]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.23it/s, loss=0.12] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.27it/s, loss=0.143]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.28it/s, loss=0.12]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.25it/s, loss=0.13]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.29it/s, loss=0.126]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.27it/s, loss=0.107]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.26it/s, loss=0.117]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.19it/s, loss=0.118]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.15it/s, loss=0.13] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.25it/s, loss=0.126] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.18it/s, loss=0.11]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.23it/s, loss=0.112] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.26it/s, loss=0.111]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.26it/s, loss=0.117] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.17it/s, loss=0.117]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.29it/s, loss=0.1]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.18it/s, loss=0.107]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.27it/s, loss=0.12]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.13it/s, loss=0.0953]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.29it/s, loss=0.11]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.22it/s, loss=0.107]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.30it/s, loss=0.116] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.28it/s, loss=0.108] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.17it/s, loss=0.119] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.28it/s, loss=0.113] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.30it/s, loss=0.111]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.28it/s, loss=0.115] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.25it/s, loss=0.105] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.30it/s, loss=0.103]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.27it/s, loss=0.131] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.27it/s, loss=0.108] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.27it/s, loss=0.116] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.27it/s, loss=0.11] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.26it/s, loss=0.108]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.25it/s, loss=0.108]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.29it/s, loss=0.107] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.27it/s, loss=0.115] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.17it/s, loss=0.111] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.28it/s, loss=0.106] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.25it/s, loss=0.108]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.27it/s, loss=0.101] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.29it/s, loss=0.116] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.29it/s, loss=0.0983]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.28it/s, loss=0.121] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.27it/s, loss=0.11]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.25it/s, loss=0.119] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.20it/s, loss=0.104] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.30it/s, loss=0.101]\n",
      "Predicting: 100%|██████████| 12/12 [00:01<00:00, 10.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building sklearn text classifier...\n",
      "Loading bert-base-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 178, validation data size: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.24it/s, loss=0.941]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.25it/s, loss=0.713]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.25it/s, loss=0.458]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.22it/s, loss=0.313]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.24it/s, loss=0.298]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.27it/s, loss=0.233]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.21it/s, loss=0.238]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.17it/s, loss=0.262]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.27it/s, loss=0.216]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.24it/s, loss=0.224]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.26it/s, loss=0.215]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.18it/s, loss=0.219]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.23it/s, loss=0.214]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.23it/s, loss=0.231]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.19it/s, loss=0.211]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.17it/s, loss=0.197]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.22it/s, loss=0.208]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.22it/s, loss=0.172]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.24it/s, loss=0.169]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.26it/s, loss=0.148] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.24it/s, loss=0.175]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.25it/s, loss=0.14] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.25it/s, loss=0.149]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.29it/s, loss=0.158]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.24it/s, loss=0.129]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.26it/s, loss=0.146] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.26it/s, loss=0.133]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.24it/s, loss=0.123]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.24it/s, loss=0.143]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.25it/s, loss=0.132] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.17it/s, loss=0.135] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.23it/s, loss=0.118]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.24it/s, loss=0.115]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.26it/s, loss=0.12]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.21it/s, loss=0.109]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.24it/s, loss=0.115] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.24it/s, loss=0.125]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.25it/s, loss=0.122] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.26it/s, loss=0.118] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.22it/s, loss=0.112]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.25it/s, loss=0.118] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.17it/s, loss=0.113] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.23it/s, loss=0.105]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.20it/s, loss=0.114]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.20it/s, loss=0.104]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.14it/s, loss=0.115] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.23it/s, loss=0.109] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.23it/s, loss=0.108]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.24it/s, loss=0.106] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.24it/s, loss=0.104] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.22it/s, loss=0.105] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.25it/s, loss=0.127] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.22it/s, loss=0.109] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.23it/s, loss=0.123]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.27it/s, loss=0.113] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.26it/s, loss=0.112] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.23it/s, loss=0.117]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.26it/s, loss=0.105] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.13it/s, loss=0.114] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.22it/s, loss=0.118]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.15it/s, loss=0.107]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.20it/s, loss=0.11] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.23it/s, loss=0.104] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.24it/s, loss=0.104] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.24it/s, loss=0.113] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.14it/s, loss=0.11] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.19it/s, loss=0.0952]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.20it/s, loss=0.108] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.23it/s, loss=0.115] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.13it/s, loss=0.104]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.17it/s, loss=0.114] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.20it/s, loss=0.131]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.19it/s, loss=0.117] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.21it/s, loss=0.115] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.25it/s, loss=0.108] \n",
      "Predicting: 100%|██████████| 12/12 [00:01<00:00, 10.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building sklearn text classifier...\n",
      "Loading bert-base-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 178, validation data size: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.20it/s, loss=0.924]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.25it/s, loss=0.608]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.13it/s, loss=0.367]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.16it/s, loss=0.288]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.22it/s, loss=0.221]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.23it/s, loss=0.241]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.15it/s, loss=0.247]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.20it/s, loss=0.198]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.25it/s, loss=0.177]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.22it/s, loss=0.163] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.24it/s, loss=0.205]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.23it/s, loss=0.131] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.25it/s, loss=0.0991]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.21it/s, loss=0.117]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.24it/s, loss=0.102]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.20it/s, loss=0.11]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.24it/s, loss=0.103] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.23it/s, loss=0.105] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.23it/s, loss=0.0959]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.20it/s, loss=0.113] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.24it/s, loss=0.0909]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.25it/s, loss=0.0838]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.25it/s, loss=0.0756]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.20it/s, loss=0.0761]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.25it/s, loss=0.0727] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.23it/s, loss=0.0712]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.20it/s, loss=0.082] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.23it/s, loss=0.0687]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.27it/s, loss=0.0754] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.25it/s, loss=0.0644]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.22it/s, loss=0.0691]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.27it/s, loss=0.0683]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.24it/s, loss=0.0657]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.27it/s, loss=0.0841]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.25it/s, loss=0.0677]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.25it/s, loss=0.0825]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.26it/s, loss=0.0734]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.26it/s, loss=0.0707] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.25it/s, loss=0.0637]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.23it/s, loss=0.0693]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.24it/s, loss=0.0635]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.13it/s, loss=0.0676]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.19it/s, loss=0.0644]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.24it/s, loss=0.0639]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.18it/s, loss=0.0652]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.24it/s, loss=0.0643]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.17it/s, loss=0.0626]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.18it/s, loss=0.0658] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.18it/s, loss=0.0799]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.24it/s, loss=0.0589]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.16it/s, loss=0.0821]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.20it/s, loss=0.0614]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.23it/s, loss=0.0679]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.22it/s, loss=0.0742]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.15it/s, loss=0.0632]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.27it/s, loss=0.0598]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.26it/s, loss=0.0784]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.27it/s, loss=0.0645]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.16it/s, loss=0.063] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.26it/s, loss=0.0626]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.23it/s, loss=0.0605]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.17it/s, loss=0.0662]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.25it/s, loss=0.0595]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.27it/s, loss=0.0659]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.14it/s, loss=0.0595]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.26it/s, loss=0.0609]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.25it/s, loss=0.0616]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.23it/s, loss=0.0574]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.19it/s, loss=0.0742]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.24it/s, loss=0.0611]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.16it/s, loss=0.0612] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.16it/s, loss=0.0611]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.22it/s, loss=0.0612]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.24it/s, loss=0.0609] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.23it/s, loss=0.0605]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.22it/s, loss=0.0752]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.27it/s, loss=0.0624]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.23it/s, loss=0.0794]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.22it/s, loss=0.0695]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.26it/s, loss=0.0561]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.17it/s, loss=0.0577] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.19it/s, loss=0.0627]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.14it/s, loss=0.0598]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.23it/s, loss=0.0599]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.16it/s, loss=0.058] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.27it/s, loss=0.0634]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.17it/s, loss=0.064] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.25it/s, loss=0.0644]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.25it/s, loss=0.0766]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.27it/s, loss=0.0635]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.26it/s, loss=0.0578] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.26it/s, loss=0.0598] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.18it/s, loss=0.0624]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.26it/s, loss=0.058] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.21it/s, loss=0.066] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.19it/s, loss=0.0643]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.26it/s, loss=0.059] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.16it/s, loss=0.0596]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.18it/s, loss=0.0629]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.15it/s, loss=0.057] \n",
      "Predicting: 100%|██████████| 12/12 [00:01<00:00, 10.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building sklearn text classifier...\n",
      "Loading bert-base-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 178, validation data size: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.20it/s, loss=0.923]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.26it/s, loss=0.609]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.23it/s, loss=0.354]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.23it/s, loss=0.264]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.15it/s, loss=0.234]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.26it/s, loss=0.21]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.25it/s, loss=0.248]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.18it/s, loss=0.215]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.25it/s, loss=0.225]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.25it/s, loss=0.241]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.17it/s, loss=0.243]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.24it/s, loss=0.196]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.25it/s, loss=0.203]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.27it/s, loss=0.197] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.25it/s, loss=0.179]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.25it/s, loss=0.156]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.27it/s, loss=0.162]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.26it/s, loss=0.139] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.28it/s, loss=0.123]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.21it/s, loss=0.134] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.26it/s, loss=0.134] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.26it/s, loss=0.128] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.20it/s, loss=0.127]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.16it/s, loss=0.118] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.22it/s, loss=0.114] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.22it/s, loss=0.114] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.26it/s, loss=0.107] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.24it/s, loss=0.115]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.22it/s, loss=0.115] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.25it/s, loss=0.116]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.23it/s, loss=0.107] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.18it/s, loss=0.104] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.23it/s, loss=0.107]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.24it/s, loss=0.111] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.23it/s, loss=0.112]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.20it/s, loss=0.137]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.25it/s, loss=0.119] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.20it/s, loss=0.0982]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.20it/s, loss=0.107] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.18it/s, loss=0.126]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.22it/s, loss=0.119] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.17it/s, loss=0.117]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.24it/s, loss=0.106]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.22it/s, loss=0.109] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.13it/s, loss=0.118] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.23it/s, loss=0.103]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.24it/s, loss=0.107] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.24it/s, loss=0.104]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.19it/s, loss=0.118]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.23it/s, loss=0.109] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.22it/s, loss=0.118] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.19it/s, loss=0.115] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.23it/s, loss=0.106]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.18it/s, loss=0.113] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.23it/s, loss=0.111] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.13it/s, loss=0.104]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.15it/s, loss=0.126] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.24it/s, loss=0.101] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.22it/s, loss=0.128] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.23it/s, loss=0.109]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.16it/s, loss=0.0979]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.24it/s, loss=0.0982]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.21it/s, loss=0.114] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.24it/s, loss=0.106] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.26it/s, loss=0.113] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.22it/s, loss=0.102] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.17it/s, loss=0.0964]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.19it/s, loss=0.0931]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.14it/s, loss=0.118] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.20it/s, loss=0.098]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.17it/s, loss=0.115] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.24it/s, loss=0.109] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.23it/s, loss=0.123] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.18it/s, loss=0.103] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.15it/s, loss=0.101] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.18it/s, loss=0.127] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.15it/s, loss=0.111] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.23it/s, loss=0.122] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.18it/s, loss=0.102] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.23it/s, loss=0.106]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.26it/s, loss=0.103] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.28it/s, loss=0.0983]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.26it/s, loss=0.0936]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.26it/s, loss=0.111] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.28it/s, loss=0.107] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.17it/s, loss=0.101]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.22it/s, loss=0.122] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.25it/s, loss=0.108] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.25it/s, loss=0.111] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.23it/s, loss=0.107] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.22it/s, loss=0.111] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.22it/s, loss=0.103] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.26it/s, loss=0.0988]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.25it/s, loss=0.114] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.25it/s, loss=0.106] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.24it/s, loss=0.108] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.20it/s, loss=0.0972]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.26it/s, loss=0.11] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.26it/s, loss=0.115] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.25it/s, loss=0.114] \n",
      "Predicting: 100%|██████████| 12/12 [00:01<00:00, 10.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building sklearn text classifier...\n",
      "Loading bert-base-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 178, validation data size: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.12it/s, loss=0.929]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.26it/s, loss=0.631]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.25it/s, loss=0.4]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.18it/s, loss=0.295]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.26it/s, loss=0.258]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.23it/s, loss=0.228] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.17it/s, loss=0.235]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.20it/s, loss=0.252]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.23it/s, loss=0.211]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.22it/s, loss=0.237]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.27it/s, loss=0.229]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.24it/s, loss=0.216]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.27it/s, loss=0.219]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.24it/s, loss=0.213]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.16it/s, loss=0.178] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.27it/s, loss=0.171]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.26it/s, loss=0.158]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.26it/s, loss=0.133] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.13it/s, loss=0.125]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.25it/s, loss=0.12]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.25it/s, loss=0.135]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.26it/s, loss=0.103] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.28it/s, loss=0.141]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.15it/s, loss=0.138]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.27it/s, loss=0.116]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.27it/s, loss=0.12]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.25it/s, loss=0.109] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.17it/s, loss=0.112]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.17it/s, loss=0.113]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.16it/s, loss=0.115] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.26it/s, loss=0.108] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.23it/s, loss=0.117] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.24it/s, loss=0.104] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.26it/s, loss=0.105] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.26it/s, loss=0.102]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.18it/s, loss=0.114]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.18it/s, loss=0.113] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.23it/s, loss=0.117] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.23it/s, loss=0.111] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.24it/s, loss=0.117]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.13it/s, loss=0.117] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.23it/s, loss=0.112] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.25it/s, loss=0.104]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.24it/s, loss=0.102]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.17it/s, loss=0.102]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.23it/s, loss=0.103] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.21it/s, loss=0.108] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.25it/s, loss=0.103]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.21it/s, loss=0.113] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.23it/s, loss=0.107]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.23it/s, loss=0.106] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.24it/s, loss=0.126] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.26it/s, loss=0.107] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.24it/s, loss=0.116] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.17it/s, loss=0.107] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.24it/s, loss=0.116] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.22it/s, loss=0.111] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.21it/s, loss=0.106]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.15it/s, loss=0.117] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.19it/s, loss=0.114]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.19it/s, loss=0.104]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.24it/s, loss=0.109]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.24it/s, loss=0.0994]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.23it/s, loss=0.102] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.14it/s, loss=0.115] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.21it/s, loss=0.107] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.24it/s, loss=0.0979]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.13it/s, loss=0.099] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.15it/s, loss=0.113] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.22it/s, loss=0.101]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.18it/s, loss=0.115] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.23it/s, loss=0.116] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.26it/s, loss=0.124] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.24it/s, loss=0.111]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.24it/s, loss=0.111] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.15it/s, loss=0.119] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.20it/s, loss=0.111] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.21it/s, loss=0.11]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.24it/s, loss=0.114] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.26it/s, loss=0.103]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.25it/s, loss=0.105] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.18it/s, loss=0.103] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.24it/s, loss=0.1]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.21it/s, loss=0.103] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.21it/s, loss=0.105] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.17it/s, loss=0.108] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.21it/s, loss=0.119] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.23it/s, loss=0.109]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.25it/s, loss=0.106] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.25it/s, loss=0.106]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.24it/s, loss=0.109] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.23it/s, loss=0.106] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.22it/s, loss=0.104] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.24it/s, loss=0.118]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.24it/s, loss=0.106]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.19it/s, loss=0.106] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.19it/s, loss=0.101] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.23it/s, loss=0.109] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.19it/s, loss=0.112] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.23it/s, loss=0.112] \n",
      "Predicting: 100%|██████████| 12/12 [00:01<00:00, 10.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building sklearn text classifier...\n",
      "Loading bert-base-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 178, validation data size: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.11it/s, loss=0.908]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.18it/s, loss=0.522]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.19it/s, loss=0.335]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.22it/s, loss=0.244]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.12it/s, loss=0.216]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.21it/s, loss=0.173]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.20it/s, loss=0.187]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.18it/s, loss=0.173] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.16it/s, loss=0.166]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.21it/s, loss=0.156] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.15it/s, loss=0.175]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.21it/s, loss=0.123] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.20it/s, loss=0.146]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.13it/s, loss=0.108] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.18it/s, loss=0.0838]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.14it/s, loss=0.097] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.19it/s, loss=0.0698]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.19it/s, loss=0.128] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.16it/s, loss=0.0767]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.19it/s, loss=0.0809]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.17it/s, loss=0.0656]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.09it/s, loss=0.0584]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.21it/s, loss=0.0815]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.20it/s, loss=0.0899]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.14it/s, loss=0.0744]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.20it/s, loss=0.0684]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.18it/s, loss=0.0773]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.19it/s, loss=0.0687]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.21it/s, loss=0.0709]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.11it/s, loss=0.0605]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.20it/s, loss=0.0655]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.11it/s, loss=0.0673]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.18it/s, loss=0.0615]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.07it/s, loss=0.143] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.12it/s, loss=0.0917]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.17it/s, loss=0.0857]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.21it/s, loss=0.0736]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.21it/s, loss=0.0686]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.14it/s, loss=0.0629]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.10it/s, loss=0.0679]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.21it/s, loss=0.0577]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.20it/s, loss=0.0621]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.14it/s, loss=0.0588]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.09it/s, loss=0.0562]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.11it/s, loss=0.0602]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.20it/s, loss=0.0647]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.18it/s, loss=0.0633]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.19it/s, loss=0.0653] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.18it/s, loss=0.081] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.08it/s, loss=0.0616]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.21it/s, loss=0.0785]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.13it/s, loss=0.0566]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.21it/s, loss=0.063] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.22it/s, loss=0.0791]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.17it/s, loss=0.0622]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.12it/s, loss=0.0562]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.23it/s, loss=0.0806]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.11it/s, loss=0.0643]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.21it/s, loss=0.0635]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.16it/s, loss=0.0624]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.15it/s, loss=0.0556]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.10it/s, loss=0.0684]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.19it/s, loss=0.0568]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.17it/s, loss=0.065] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.21it/s, loss=0.061] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.19it/s, loss=0.0602]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.16it/s, loss=0.0602]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.16it/s, loss=0.0576] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.19it/s, loss=0.0694]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.21it/s, loss=0.0632]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.10it/s, loss=0.0654] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.12it/s, loss=0.0628]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.24it/s, loss=0.0537]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.16it/s, loss=0.0622] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.19it/s, loss=0.0595]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.18it/s, loss=0.0796]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.08it/s, loss=0.0631]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.21it/s, loss=0.0786]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.20it/s, loss=0.0629]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.17it/s, loss=0.0552]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.12it/s, loss=0.0572]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.12it/s, loss=0.0608]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.23it/s, loss=0.0587]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.12it/s, loss=0.0559]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.15it/s, loss=0.0628]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.21it/s, loss=0.0603]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.17it/s, loss=0.0651]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.17it/s, loss=0.0645]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.19it/s, loss=0.0774]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.20it/s, loss=0.0653]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.22it/s, loss=0.0528] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.20it/s, loss=0.0602] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.15it/s, loss=0.062] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.18it/s, loss=0.0536]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.20it/s, loss=0.0627]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.22it/s, loss=0.0641]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.14it/s, loss=0.0558]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.19it/s, loss=0.0555]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.20it/s, loss=0.0621]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.18it/s, loss=0.0577]\n",
      "Predicting: 100%|██████████| 12/12 [00:01<00:00,  9.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building sklearn text classifier...\n",
      "Loading bert-base-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 178, validation data size: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.20it/s, loss=0.908]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.07it/s, loss=0.54] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.17it/s, loss=0.325]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.07it/s, loss=0.249]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.16it/s, loss=0.23] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.14it/s, loss=0.221] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.13it/s, loss=0.251]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.16it/s, loss=0.212]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.14it/s, loss=0.198]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.18it/s, loss=0.201]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.17it/s, loss=0.2]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.14it/s, loss=0.152] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.08it/s, loss=0.173]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.12it/s, loss=0.17]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.165] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.10it/s, loss=0.146] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.10it/s, loss=0.144] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.12it/s, loss=0.153] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.16it/s, loss=0.138] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.10it/s, loss=0.126] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.19it/s, loss=0.137] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.14it/s, loss=0.126] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.15it/s, loss=0.128]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.14it/s, loss=0.119] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.14it/s, loss=0.113]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.13it/s, loss=0.125] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.13it/s, loss=0.103]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.09it/s, loss=0.105]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.16it/s, loss=0.111]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.18it/s, loss=0.117] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.15it/s, loss=0.112] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.16it/s, loss=0.106]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.16it/s, loss=0.0997]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.14it/s, loss=0.112] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.18it/s, loss=0.106]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.21it/s, loss=0.118] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.20it/s, loss=0.111] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.16it/s, loss=0.111] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.16it/s, loss=0.114] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.16it/s, loss=0.11]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.13it/s, loss=0.11]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.16it/s, loss=0.113]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.08it/s, loss=0.0981]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.17it/s, loss=0.104]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.18it/s, loss=0.117] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.15it/s, loss=0.0975]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.21it/s, loss=0.102] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.10it/s, loss=0.107]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.11it/s, loss=0.108] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.07it/s, loss=0.105] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.18it/s, loss=0.113] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.15it/s, loss=0.116] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.11it/s, loss=0.108]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.16it/s, loss=0.122]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.14it/s, loss=0.109] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.14it/s, loss=0.11] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.16it/s, loss=0.129] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.15it/s, loss=0.114] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.11it/s, loss=0.117] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.15it/s, loss=0.107]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.17it/s, loss=0.102]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.10it/s, loss=0.1]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.09it/s, loss=0.1]   \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.16it/s, loss=0.109] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.18it/s, loss=0.106] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.11it/s, loss=0.106] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.14it/s, loss=0.0959]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.12it/s, loss=0.102]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.15it/s, loss=0.116] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.18it/s, loss=0.0985]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.18it/s, loss=0.119] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.21it/s, loss=0.109] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.16it/s, loss=0.121] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.15it/s, loss=0.0998]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.20it/s, loss=0.106]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.19it/s, loss=0.122] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.18it/s, loss=0.101] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.16it/s, loss=0.122] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.15it/s, loss=0.108] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.17it/s, loss=0.107] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.19it/s, loss=0.0988]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.17it/s, loss=0.105]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.15it/s, loss=0.103]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.21it/s, loss=0.105] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.15it/s, loss=0.11]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.17it/s, loss=0.106]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.09it/s, loss=0.112] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.17it/s, loss=0.107] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.16it/s, loss=0.111] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.13it/s, loss=0.102] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.15it/s, loss=0.106] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.15it/s, loss=0.107] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.16it/s, loss=0.104] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.11it/s, loss=0.109] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.16it/s, loss=0.102] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.16it/s, loss=0.102]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.18it/s, loss=0.0992]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.18it/s, loss=0.102]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.18it/s, loss=0.103] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.16it/s, loss=0.106] \n",
      "Predicting: 100%|██████████| 12/12 [00:01<00:00,  9.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building sklearn text classifier...\n",
      "Loading bert-base-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 178, validation data size: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.11it/s, loss=0.915]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.12it/s, loss=0.565]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.08it/s, loss=0.354]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.13it/s, loss=0.276]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.245]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.00it/s, loss=0.239] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.15it/s, loss=0.23] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.09it/s, loss=0.243] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.13it/s, loss=0.209]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.205]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.10it/s, loss=0.16] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.14it/s, loss=0.145]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.13it/s, loss=0.162]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.12it/s, loss=0.15]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.06it/s, loss=0.164] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.12it/s, loss=0.158] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.14it/s, loss=0.17] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.12it/s, loss=0.132] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.15it/s, loss=0.125]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.14it/s, loss=0.116] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.08it/s, loss=0.131] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.15it/s, loss=0.131]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.12it/s, loss=0.135]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.12it/s, loss=0.138]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.11it/s, loss=0.114]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.15it/s, loss=0.131] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.11it/s, loss=0.115] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.122] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.09it/s, loss=0.123]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.11it/s, loss=0.129] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.08it/s, loss=0.121] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.13it/s, loss=0.119] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.11it/s, loss=0.114]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.12it/s, loss=0.108] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.14it/s, loss=0.105]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.09it/s, loss=0.112] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.07it/s, loss=0.108] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.13it/s, loss=0.116] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.13it/s, loss=0.107] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.17it/s, loss=0.113]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.10it/s, loss=0.132] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.08it/s, loss=0.119] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.09it/s, loss=0.105]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.09it/s, loss=0.106]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.11it/s, loss=0.106]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.12it/s, loss=0.101] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.12it/s, loss=0.109] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.15it/s, loss=0.101]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.10it/s, loss=0.105] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.08it/s, loss=0.107]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.12it/s, loss=0.107] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.14it/s, loss=0.121] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.10it/s, loss=0.107] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.14it/s, loss=0.123] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.13it/s, loss=0.112] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.14it/s, loss=0.117] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.113] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.14it/s, loss=0.109] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.10it/s, loss=0.116] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.12it/s, loss=0.113]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.14it/s, loss=0.109]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.13it/s, loss=0.112]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.09it/s, loss=0.0996]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.10it/s, loss=0.106] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.111] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.10it/s, loss=0.107] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.09it/s, loss=0.0985]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.0986]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.14it/s, loss=0.112] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.06it/s, loss=0.102]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.10it/s, loss=0.115] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.07it/s, loss=0.115] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.09it/s, loss=0.127] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.14it/s, loss=0.107] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.12it/s, loss=0.106] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.08it/s, loss=0.112] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.11it/s, loss=0.115] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.113] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.11it/s, loss=0.104] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.16it/s, loss=0.1]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.14it/s, loss=0.0999]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.11it/s, loss=0.103] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.13it/s, loss=0.102]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.12it/s, loss=0.104] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.106]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.14it/s, loss=0.111]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.11it/s, loss=0.114] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.13it/s, loss=0.106]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.06it/s, loss=0.104] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.09it/s, loss=0.104]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.09it/s, loss=0.109] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.09it/s, loss=0.109] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.15it/s, loss=0.103]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.12it/s, loss=0.115] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.1]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.13it/s, loss=0.11]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.13it/s, loss=0.101] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.16it/s, loss=0.108] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.06it/s, loss=0.115] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.07it/s, loss=0.11]  \n",
      "Predicting: 100%|██████████| 12/12 [00:01<00:00,  9.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building sklearn text classifier...\n",
      "Loading bert-base-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 178, validation data size: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.10it/s, loss=0.943]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.11it/s, loss=0.746]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.14it/s, loss=0.463]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.10it/s, loss=0.339]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.16it/s, loss=0.259]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.227]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.17it/s, loss=0.202]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.17it/s, loss=0.177] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.16it/s, loss=0.175]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.15it/s, loss=0.168]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.14it/s, loss=0.227]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.14it/s, loss=0.186] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.15it/s, loss=0.185] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.156] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.13it/s, loss=0.181]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.13it/s, loss=0.161]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.08it/s, loss=0.15] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.10it/s, loss=0.138]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.15it/s, loss=0.108] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.10it/s, loss=0.119] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.15it/s, loss=0.1]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.14it/s, loss=0.0892]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.11it/s, loss=0.0816]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.15it/s, loss=0.0762]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.13it/s, loss=0.0703]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.15it/s, loss=0.0716]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.08it/s, loss=0.078] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.12it/s, loss=0.0703]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.08it/s, loss=0.0758]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.16it/s, loss=0.0688]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.14it/s, loss=0.0634]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.14it/s, loss=0.0711]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.11it/s, loss=0.0587]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.15it/s, loss=0.0843]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.09it/s, loss=0.0745]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.14it/s, loss=0.0826]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.16it/s, loss=0.0713]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.12it/s, loss=0.0798]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.15it/s, loss=0.0667]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.14it/s, loss=0.0673]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.06it/s, loss=0.06]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.09it/s, loss=0.0614]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.14it/s, loss=0.0605]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.12it/s, loss=0.063] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.13it/s, loss=0.0668]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.12it/s, loss=0.0686]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.13it/s, loss=0.0585]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.13it/s, loss=0.064]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.0767]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.14it/s, loss=0.059] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.083] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.13it/s, loss=0.0644]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.15it/s, loss=0.0589]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.14it/s, loss=0.0672]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.16it/s, loss=0.0541]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.18it/s, loss=0.0633]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.15it/s, loss=0.084] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.13it/s, loss=0.0658]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.11it/s, loss=0.0649]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.13it/s, loss=0.0621]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.12it/s, loss=0.0599]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.08it/s, loss=0.068] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.13it/s, loss=0.0628]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.10it/s, loss=0.0597]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.14it/s, loss=0.0598]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.15it/s, loss=0.064] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.16it/s, loss=0.0614]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.0566] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.07it/s, loss=0.0721]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.11it/s, loss=0.0652]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.0645] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.14it/s, loss=0.0629]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.16it/s, loss=0.0588]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.18it/s, loss=0.0631]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.15it/s, loss=0.0609]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.17it/s, loss=0.0781]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.11it/s, loss=0.0653]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.12it/s, loss=0.0784]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.14it/s, loss=0.0657]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.13it/s, loss=0.0571]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.15it/s, loss=0.0572] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.06it/s, loss=0.0596]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.17it/s, loss=0.0612]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.14it/s, loss=0.0571]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.07it/s, loss=0.0608]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.15it/s, loss=0.0607]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.17it/s, loss=0.0633]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.08it/s, loss=0.0656]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.17it/s, loss=0.0771]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.14it/s, loss=0.064] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.13it/s, loss=0.0569] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.09it/s, loss=0.064]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.14it/s, loss=0.0621]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.06it/s, loss=0.0568]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.14it/s, loss=0.0677]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.09it/s, loss=0.0658]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.12it/s, loss=0.0572]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.15it/s, loss=0.0598]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.12it/s, loss=0.0667]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.11it/s, loss=0.0604]\n",
      "Predicting: 100%|██████████| 12/12 [00:01<00:00,  9.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building sklearn text classifier...\n",
      "Loading bert-base-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 178, validation data size: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.09it/s, loss=0.94] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.16it/s, loss=0.747]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.11it/s, loss=0.454]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.14it/s, loss=0.323]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.15it/s, loss=0.287]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.14it/s, loss=0.236]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.11it/s, loss=0.251]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.08it/s, loss=0.23] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.12it/s, loss=0.209]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.14it/s, loss=0.213]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.14it/s, loss=0.224]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.13it/s, loss=0.192]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.08it/s, loss=0.225]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.16it/s, loss=0.232] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.10it/s, loss=0.214]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.10it/s, loss=0.216]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.06it/s, loss=0.208] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.15it/s, loss=0.194] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.13it/s, loss=0.186]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.07it/s, loss=0.183]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.07it/s, loss=0.193]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.06it/s, loss=0.165]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.17it/s, loss=0.17] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.07it/s, loss=0.16] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.13it/s, loss=0.142]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.15it/s, loss=0.15] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.14it/s, loss=0.136]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.07it/s, loss=0.121]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.09it/s, loss=0.156]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.14it/s, loss=0.118] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.10it/s, loss=0.126] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.13it/s, loss=0.115]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.13it/s, loss=0.106]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.12it/s, loss=0.125]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.114]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.15it/s, loss=0.129] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.15it/s, loss=0.124] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.12it/s, loss=0.113] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.14it/s, loss=0.115] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.11it/s, loss=0.115]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.13it/s, loss=0.116] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.09it/s, loss=0.12] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.101]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.11it/s, loss=0.105] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.12it/s, loss=0.12] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.16it/s, loss=0.0988]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.12it/s, loss=0.106] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.14it/s, loss=0.111]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.16it/s, loss=0.124]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.09it/s, loss=0.114] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.09it/s, loss=0.121] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.121] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.16it/s, loss=0.11] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.15it/s, loss=0.124]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.16it/s, loss=0.116] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.15it/s, loss=0.105]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.18it/s, loss=0.125] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.15it/s, loss=0.115] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.16it/s, loss=0.114] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.18it/s, loss=0.105]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.15it/s, loss=0.102]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.07it/s, loss=0.103] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.14it/s, loss=0.105] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.12it/s, loss=0.102] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.14it/s, loss=0.12]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.104] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.0983]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.08it/s, loss=0.104] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.06it/s, loss=0.115] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.16it/s, loss=0.101]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.10it/s, loss=0.118] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.13it/s, loss=0.115] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.10it/s, loss=0.126] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.14it/s, loss=0.109]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.106]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.12it/s, loss=0.124] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.15it/s, loss=0.105] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.07it/s, loss=0.119] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.17it/s, loss=0.111] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.07it/s, loss=0.105] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.15it/s, loss=0.0952]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.14it/s, loss=0.104]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.09it/s, loss=0.1]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.11it/s, loss=0.109] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.13it/s, loss=0.115] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.12it/s, loss=0.111]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.15it/s, loss=0.116] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.16it/s, loss=0.103] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.117] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.13it/s, loss=0.102] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.14it/s, loss=0.111] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.18it/s, loss=0.106] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.13it/s, loss=0.103] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.14it/s, loss=0.116] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.108]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.10it/s, loss=0.103]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.09it/s, loss=0.102] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.15it/s, loss=0.106]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.10it/s, loss=0.1]   \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.13it/s, loss=0.116] \n",
      "Predicting: 100%|██████████| 12/12 [00:01<00:00,  9.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building sklearn text classifier...\n",
      "Loading bert-base-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 178, validation data size: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.06it/s, loss=0.947]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.08it/s, loss=0.754]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.15it/s, loss=0.504]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.12it/s, loss=0.333]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.15it/s, loss=0.302]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.14it/s, loss=0.248]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.06it/s, loss=0.248]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.12it/s, loss=0.252]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.208]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.17it/s, loss=0.21] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.18it/s, loss=0.209]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.11it/s, loss=0.207]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.09it/s, loss=0.214]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.237]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.15it/s, loss=0.216] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.213]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.06it/s, loss=0.215]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.07it/s, loss=0.186]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.14it/s, loss=0.184]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.16]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.14it/s, loss=0.184]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.13it/s, loss=0.15] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.15it/s, loss=0.159]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.16it/s, loss=0.161]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.14it/s, loss=0.144]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.17it/s, loss=0.151] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.17it/s, loss=0.141] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.08it/s, loss=0.131]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.18it/s, loss=0.129]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.16it/s, loss=0.131] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.15it/s, loss=0.123] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.15it/s, loss=0.113] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.104]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.17it/s, loss=0.117] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.15it/s, loss=0.106]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.15it/s, loss=0.129] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.118]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.06it/s, loss=0.14]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.14it/s, loss=0.118] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.09it/s, loss=0.126]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.11it/s, loss=0.125] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.117] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.11it/s, loss=0.0963]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.10it/s, loss=0.111]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.15it/s, loss=0.108]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.15it/s, loss=0.112] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.11it/s, loss=0.117]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.16it/s, loss=0.11] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.12it/s, loss=0.11]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.07it/s, loss=0.112]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.07it/s, loss=0.107]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.16it/s, loss=0.135] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.12it/s, loss=0.11]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.12] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.10it/s, loss=0.114] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.15it/s, loss=0.114] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.09it/s, loss=0.118] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.08it/s, loss=0.105] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.11it/s, loss=0.122]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.15it/s, loss=0.122]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.15it/s, loss=0.108]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.12it/s, loss=0.111]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.14it/s, loss=0.104] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.09it/s, loss=0.102] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.14it/s, loss=0.121] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.09it/s, loss=0.1]   \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.14it/s, loss=0.0972]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.15it/s, loss=0.102] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.11it/s, loss=0.115] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.13it/s, loss=0.101]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.07it/s, loss=0.118] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.13it/s, loss=0.124]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.09it/s, loss=0.128] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.13it/s, loss=0.127] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.14it/s, loss=0.109] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.12it/s, loss=0.115] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.16it/s, loss=0.112] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.17it/s, loss=0.111] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.16it/s, loss=0.116] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.06it/s, loss=0.113]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.105] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.11] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.18it/s, loss=0.0991]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.17it/s, loss=0.11]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.16it/s, loss=0.106] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.11]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.12it/s, loss=0.117] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.11it/s, loss=0.115]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.109] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.17it/s, loss=0.106]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.07it/s, loss=0.113] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.17it/s, loss=0.105] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.08it/s, loss=0.101]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.10it/s, loss=0.123] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.11it/s, loss=0.108]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.07it/s, loss=0.104] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.06it/s, loss=0.11]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.11it/s, loss=0.111] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.14it/s, loss=0.115] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.13it/s, loss=0.115] \n",
      "Predicting: 100%|██████████| 12/12 [00:01<00:00,  9.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building sklearn text classifier...\n",
      "Building sklearn text classifier...\n",
      "Loading bert-base-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 267, validation data size: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.40it/s, loss=0.781]\n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.41it/s, loss=0.346]\n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.36it/s, loss=0.259]\n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.30it/s, loss=0.211]\n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.42it/s, loss=0.222]\n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.39it/s, loss=0.195]\n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.40it/s, loss=0.194]\n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.38it/s, loss=0.179]\n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.27it/s, loss=0.156]\n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.31it/s, loss=0.145] \n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.30it/s, loss=0.204] \n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.27it/s, loss=0.189]\n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.27it/s, loss=0.162] \n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.41it/s, loss=0.181]\n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.43it/s, loss=0.176]\n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.34it/s, loss=0.149]\n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.44it/s, loss=0.145] \n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.44it/s, loss=0.15]  \n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.39it/s, loss=0.121]\n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.30it/s, loss=0.145] \n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.40it/s, loss=0.12] \n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.43it/s, loss=0.114] \n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.36it/s, loss=0.118] \n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.41it/s, loss=0.115]\n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.38it/s, loss=0.115] \n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.43it/s, loss=0.162] \n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.32it/s, loss=0.116]\n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.38it/s, loss=0.116] \n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.41it/s, loss=0.102] \n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.36it/s, loss=0.106] \n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.42it/s, loss=0.11]  \n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.35it/s, loss=0.137] \n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.43it/s, loss=0.122] \n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.42it/s, loss=0.117] \n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.36it/s, loss=0.11] \n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.36it/s, loss=0.115] \n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.45it/s, loss=0.102] \n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.38it/s, loss=0.125] \n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.37it/s, loss=0.0942]\n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.42it/s, loss=0.0937]\n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.37it/s, loss=0.101] \n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.39it/s, loss=0.0925]\n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.37it/s, loss=0.0965]\n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.40it/s, loss=0.0984]\n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.30it/s, loss=0.102] \n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.35it/s, loss=0.107] \n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.40it/s, loss=0.0963]\n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.43it/s, loss=0.0927]\n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.38it/s, loss=0.0959]\n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.29it/s, loss=0.089] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=BertClassifier(max_seq_length=64, validation_fraction=0),\n",
       "             param_grid={'epochs': [50, 75, 100],\n",
       "                         'learning_rate': [2e-05, 3e-05, 1e-05]},\n",
       "             scoring='accuracy', verbose=True)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%time\n",
    "# from bert import run_classifier\n",
    "params = {'epochs':[50, 75, 100], 'learning_rate':[2e-5, 3e-5, 1e-5]}\n",
    "\n",
    "# wrap classifier/regressor in GridSearchCV\n",
    "clf_bert = GridSearchCV(BertClassifier(validation_fraction=0, max_seq_length=64), \n",
    "                   params,\n",
    "                   cv=3,\n",
    "                   scoring='accuracy',\n",
    "                   verbose=True)\n",
    "\n",
    "# fit gridsearch \n",
    "clf_bert.fit(X_train ,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.918 (+/-0.046) for {'epochs': 50, 'learning_rate': 2e-05}\n",
      "0.921 (+/-0.055) for {'epochs': 50, 'learning_rate': 3e-05}\n",
      "0.918 (+/-0.046) for {'epochs': 50, 'learning_rate': 1e-05}\n",
      "0.921 (+/-0.049) for {'epochs': 75, 'learning_rate': 2e-05}\n",
      "0.918 (+/-0.046) for {'epochs': 75, 'learning_rate': 3e-05}\n",
      "0.914 (+/-0.046) for {'epochs': 75, 'learning_rate': 1e-05}\n",
      "0.921 (+/-0.037) for {'epochs': 100, 'learning_rate': 2e-05}\n",
      "0.918 (+/-0.038) for {'epochs': 100, 'learning_rate': 3e-05}\n",
      "0.918 (+/-0.038) for {'epochs': 100, 'learning_rate': 1e-05}\n",
      "\n",
      "Best score: 0.9213483146067416 with params: {'epochs': 50, 'learning_rate': 3e-05}\n"
     ]
    }
   ],
   "source": [
    "means = clf_bert.cv_results_['mean_test_score']\n",
    "stds = clf_bert.cv_results_['std_test_score']\n",
    "\n",
    "for mean, std, params in zip(means, stds, clf_bert.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "        \n",
    "# best scores\n",
    "print(\"\\nBest score:\", clf_bert.best_score_,\"with params:\", clf_bert.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tesla P100-PCIE-16GB'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CUDA device (GPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "torch.cuda.get_device_name(0)\n",
    "# Print state of GPU\n",
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a batch size\n",
    "batch_size = 5\n",
    "epochs = 50\n",
    "learning_rate = 3e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = {'control': 0, 'case': 1}\n",
    "# initialise the model use pretrained bert_2 instance and the label numbers\n",
    "model = BERT_Text_Classifier(bert, class_num=len(categories))\n",
    "\n",
    "# push the model to GPU\n",
    "model = model.to(device)\n",
    "\n",
    "# define the optimizer\n",
    "# optimizer = AdamW(model.parameters(),\n",
    "#                   lr = learning_rate)\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "cross_entropy  = nn.NLLLoss() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:02<00:00, 23.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 81.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.550 dev performance, p:0.808, r:0.926, f1:0.863\n",
      "current best score is 0.863\n",
      "\n",
      " Epoch 2 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:02<00:00, 23.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 86.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.543 dev performance, p:0.787, r:0.926, f1:0.851\n",
      "\n",
      " Epoch 3 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:02<00:00, 23.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 87.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.540 dev performance, p:0.818, r:0.926, f1:0.869\n",
      "current best score is 0.869\n",
      "\n",
      " Epoch 4 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:02<00:00, 23.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 81.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.532 dev performance, p:0.785, r:0.912, f1:0.844\n",
      "\n",
      " Epoch 5 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:02<00:00, 23.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 82.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.523 dev performance, p:0.778, r:0.926, f1:0.846\n",
      "\n",
      " Epoch 6 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:02<00:00, 23.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 88.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.521 dev performance, p:0.797, r:0.926, f1:0.857\n",
      "\n",
      " Epoch 7 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:02<00:00, 23.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 88.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.507 dev performance, p:0.816, r:0.912, f1:0.861\n",
      "\n",
      " Epoch 8 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:02<00:00, 23.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 88.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.507 dev performance, p:0.797, r:0.926, f1:0.857\n",
      "\n",
      " Epoch 9 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:02<00:00, 23.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 82.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.502 dev performance, p:0.865, r:0.941, f1:0.901\n",
      "current best score is 0.901\n",
      "\n",
      " Epoch 10 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:02<00:00, 23.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 88.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.487 dev performance, p:0.797, r:0.926, f1:0.857\n",
      "\n",
      " Epoch 11 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:02<00:00, 23.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 88.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.486 dev performance, p:0.797, r:0.926, f1:0.857\n",
      "\n",
      " Epoch 12 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 28.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 111.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.477 dev performance, p:0.816, r:0.912, f1:0.861\n",
      "\n",
      " Epoch 13 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 29.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 112.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.478 dev performance, p:0.808, r:0.926, f1:0.863\n",
      "\n",
      " Epoch 14 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 28.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 110.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.466 dev performance, p:0.829, r:0.926, f1:0.875\n",
      "\n",
      " Epoch 15 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 28.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 110.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.459 dev performance, p:0.821, r:0.941, f1:0.877\n",
      "\n",
      " Epoch 16 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 28.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 109.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.458 dev performance, p:0.842, r:0.941, f1:0.889\n",
      "\n",
      " Epoch 17 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 28.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 109.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.454 dev performance, p:0.829, r:0.926, f1:0.875\n",
      "\n",
      " Epoch 18 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 28.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 109.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.445 dev performance, p:0.821, r:0.941, f1:0.877\n",
      "\n",
      " Epoch 19 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 28.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 112.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.443 dev performance, p:0.875, r:0.926, f1:0.900\n",
      "\n",
      " Epoch 20 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 28.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 112.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.437 dev performance, p:0.829, r:0.926, f1:0.875\n",
      "\n",
      " Epoch 21 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 28.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 112.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.430 dev performance, p:0.875, r:0.926, f1:0.900\n",
      "\n",
      " Epoch 22 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 28.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 112.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.420 dev performance, p:0.853, r:0.941, f1:0.895\n",
      "\n",
      " Epoch 23 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 28.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 88.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.418 dev performance, p:0.810, r:0.941, f1:0.871\n",
      "\n",
      " Epoch 24 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:02<00:00, 23.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 87.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.413 dev performance, p:0.890, r:0.956, f1:0.922\n",
      "current best score is 0.922\n",
      "\n",
      " Epoch 25 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:02<00:00, 23.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 88.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.412 dev performance, p:0.863, r:0.926, f1:0.894\n",
      "\n",
      " Epoch 26 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:02<00:00, 24.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 111.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.405 dev performance, p:0.878, r:0.956, f1:0.915\n",
      "\n",
      " Epoch 27 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 28.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 111.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.402 dev performance, p:0.855, r:0.956, f1:0.903\n",
      "\n",
      " Epoch 28 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 28.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 111.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.397 dev performance, p:0.875, r:0.926, f1:0.900\n",
      "\n",
      " Epoch 29 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 28.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 109.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.400 dev performance, p:0.900, r:0.926, f1:0.913\n",
      "\n",
      " Epoch 30 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 28.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 111.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.391 dev performance, p:0.863, r:0.926, f1:0.894\n",
      "\n",
      " Epoch 31 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 28.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 111.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.382 dev performance, p:0.889, r:0.941, f1:0.914\n",
      "\n",
      " Epoch 32 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 28.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 111.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.380 dev performance, p:0.867, r:0.956, f1:0.909\n",
      "\n",
      " Epoch 33 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 27.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 88.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.378 dev performance, p:0.915, r:0.956, f1:0.935\n",
      "current best score is 0.935\n",
      "\n",
      " Epoch 34 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:02<00:00, 24.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 82.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.372 dev performance, p:0.915, r:0.956, f1:0.935\n",
      "\n",
      " Epoch 35 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:02<00:00, 23.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 108.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.368 dev performance, p:0.913, r:0.926, f1:0.920\n",
      "\n",
      " Epoch 36 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:02<00:00, 24.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 88.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.367 dev performance, p:0.901, r:0.941, f1:0.921\n",
      "\n",
      " Epoch 37 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:02<00:00, 23.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 88.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.362 dev performance, p:0.917, r:0.971, f1:0.943\n",
      "current best score is 0.943\n",
      "\n",
      " Epoch 38 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:02<00:00, 25.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 110.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.359 dev performance, p:0.969, r:0.912, f1:0.939\n",
      "\n",
      " Epoch 39 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:02<00:00, 25.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 110.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.353 dev performance, p:0.926, r:0.926, f1:0.926\n",
      "\n",
      " Epoch 40 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:02<00:00, 25.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 94.04it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.350 dev performance, p:0.943, r:0.971, f1:0.957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current best score is 0.957\n",
      "\n",
      " Epoch 41 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:02<00:00, 25.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 111.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.351 dev performance, p:0.887, r:0.926, f1:0.906\n",
      "\n",
      " Epoch 42 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:02<00:00, 25.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 111.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.342 dev performance, p:0.903, r:0.956, f1:0.929\n",
      "\n",
      " Epoch 43 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:02<00:00, 25.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 111.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.339 dev performance, p:0.929, r:0.956, f1:0.942\n",
      "\n",
      " Epoch 44 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:02<00:00, 25.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 111.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.341 dev performance, p:0.890, r:0.956, f1:0.922\n",
      "\n",
      " Epoch 45 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:02<00:00, 25.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 112.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.333 dev performance, p:0.943, r:0.971, f1:0.957\n",
      "\n",
      " Epoch 46 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:02<00:00, 25.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 111.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.337 dev performance, p:0.941, r:0.941, f1:0.941\n",
      "\n",
      " Epoch 47 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:02<00:00, 25.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 94.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.330 dev performance, p:0.942, r:0.956, f1:0.949\n",
      "\n",
      " Epoch 48 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:02<00:00, 25.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 94.55it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.326 dev performance, p:0.941, r:0.941, f1:0.941\n",
      "\n",
      " Epoch 49 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:02<00:00, 25.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 111.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.325 dev performance, p:0.928, r:0.941, f1:0.934\n",
      "\n",
      " Epoch 50 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:02<00:00, 25.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 110.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.327 dev performance, p:0.941, r:0.941, f1:0.941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#for each epoch\n",
    "\n",
    "best_model_state = None\n",
    "best_score = -1\n",
    "\n",
    "for epoch in range(epochs):\n",
    "     \n",
    "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs), flush=True)\n",
    "    #train model\n",
    "    train_loss, performance = train()\n",
    "    print('\\nTraining Loss: {:.3f}'.format(train_loss), \n",
    "          'dev performance, p:{precision:.3f}, r:{recall:.3f}, f1:{f1:.3f}'.format(**performance), flush=True)\n",
    "    if best_score < performance['f1']:\n",
    "        best_score = performance['f1']\n",
    "        best_model_state = copy.deepcopy(model.state_dict())\n",
    "        print('current best score is {0:.3f}'.format(best_score), flush=True)    \n",
    "\n",
    "ran = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = 'MEH_bert_gridsearch.pt'\n",
    "torch.save(best_model_state, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not ran:\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    model_file = 'MEH_bert_gridsearch.pt'\n",
    "\n",
    "    categories = {'control': 0, 'case': 1}\n",
    "    # initialise the model use pretrained bert instance and the label numbers\n",
    "    model = BERT_Text_Classifier(bert_2, class_num=len(categories))\n",
    "\n",
    "    model.load_state_dict(torch.load(model_file))\n",
    "    model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seq = test_seq.to(device)\n",
    "test_mask = test_mask.to(device)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:00<00:00, 110.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': 0.9466666666666667, 'recall': 0.9466666666666667, 'f1': 0.9466666666666667}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# dataLoader for test set\n",
    "# wrap tensors\n",
    "testing_data = TensorDataset(test_seq, test_mask, test_y)\n",
    "testing_data_loader = DataLoader(testing_data, batch_size=batch_size)     \n",
    "print(evaluate(model, testing_data_loader))\n",
    "# preds = np.argmax(preds.detach().cpu(), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.73      0.73        15\n",
      "           1       0.95      0.95      0.95        75\n",
      "\n",
      "    accuracy                           0.91        90\n",
      "   macro avg       0.84      0.84      0.84        90\n",
      "weighted avg       0.91      0.91      0.91        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predicting, so gradients\n",
    "with torch.no_grad():\n",
    "    preds = model(test_seq, test_mask)\n",
    "    \n",
    "preds = np.argmax(preds.detach().cpu(), axis = 1)\n",
    "print(classification_report(test_y, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_bert_grid = confusion_matrix(test_y, preds, labels=[1,0])\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cm_bert_grid, annot=True, ax = ax, cmap='Blues', fmt=\"d\")\n",
    "\n",
    "ax.set_title('Confusion Matrix of BERT after Grid Search (MEH data)')\n",
    "\n",
    "ax.set_xlabel('Predicted Labels')\n",
    "ax.set_ylabel('True Labels')\n",
    "\n",
    "ax.xaxis.set_ticklabels(['FAKE', 'REAL'])\n",
    "ax.yaxis.set_ticklabels(['FAKE', 'REAL'])\n",
    "plt.savefig('Confusion_matrix_BERT(grid search)_meh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BlueBERT\n",
    "## Initial training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bionlp/bluebert_pubmed_mimic_uncased_L-12_H-768_A-12 were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# bionlp/bluebert_pubmed_mimic_uncased_L-12_H-768_A-12\n",
    "# import BERT-base pretrained model\n",
    "bert_2 = AutoModel.from_pretrained('bionlp/bluebert_pubmed_mimic_uncased_L-12_H-768_A-12')\n",
    "# Load the BERT tokenizer\n",
    "tokenizer_2 = BertTokenizerFast.from_pretrained('bionlp/bluebert_pubmed_mimic_uncased_L-12_H-768_A-12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "def prepare_X_y(texts, labels):    \n",
    "    tokenized = tokenizer_2.batch_encode_plus(\n",
    "        texts,\n",
    "        padding=True,\n",
    "        truncation=True\n",
    "    )\n",
    "    seq = torch.tensor(tokenized['input_ids'])\n",
    "    mask = torch.tensor(tokenized['attention_mask'])\n",
    "    y = torch.tensor(labels)\n",
    "    return seq, mask, y\n",
    "\n",
    "train_seq, train_mask, train_y = prepare_X_y(X_train, y_train)\n",
    "dev_seq, dev_mask, dev_y = prepare_X_y(X_dev, y_dev)\n",
    "test_seq, test_mask, test_y = prepare_X_y(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a batch size\n",
    "batch_size = 5\n",
    "epochs = 20\n",
    "learning_rate = 1e-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrap tensors\n",
    "training_data = TensorDataset(train_seq, train_mask, train_y)\n",
    "dev_data = TensorDataset(dev_seq, dev_mask, dev_y)\n",
    "# testing_data = TensorDataset(test_seq, test_mask, test_y)\n",
    "\n",
    "# sampler for sampling the data during training\n",
    "sampler = RandomSampler(training_data)\n",
    "\n",
    "# dataLoader\n",
    "training_data_loader = DataLoader(training_data, sampler=sampler, batch_size=batch_size)\n",
    "dev_data_loader = DataLoader(dev_data, batch_size=batch_size) \n",
    "# testing_data_loader = DataLoader(testing_data, sampler=sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "\n",
    "class BERT_Text_Classifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, bert_2, class_num, bert_dim=768, hidden_dim=512):\n",
    "      \n",
    "        super(BERT_Text_Classifier, self).__init__()\n",
    "\n",
    "        self.bert_2 = bert_2 \n",
    "\n",
    "        # define a dropout\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "        # use relu\n",
    "        self.relu =  nn.ReLU()\n",
    "\n",
    "        # feedforward layer\n",
    "        self.fc1 = nn.Linear(bert_dim, hidden_dim)\n",
    "\n",
    "        # Output layer\n",
    "        self.fc2 = nn.Linear(hidden_dim, class_num)\n",
    "\n",
    "        #softmax function instance\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    #define the forward pass\n",
    "    def forward(self, seq, mask):\n",
    "\n",
    "        # use pretrained bert_2 to read the sequence with the mask (pay attention to which tokens)\n",
    "        bert_out = self.bert_2(seq, attention_mask=mask)\n",
    "        \n",
    "        # print('last_hidden_state', bert_out['last_hidden_state'].size(), \n",
    "        #      'pooler_output', bert_out['pooler_output'].size())\n",
    "        \n",
    "        lhs = bert_out['pooler_output']\n",
    "        x = self.fc1(lhs)        \n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        # apply softmax activation\n",
    "        x = self.softmax(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(m, evl_loader, eval_labels=[1]):\n",
    "    from sklearn.metrics import precision_recall_fscore_support\n",
    "    preds = []\n",
    "    lbls = []\n",
    "    print('evaluating...', flush=True)\n",
    "    for step, batch in enumerate(tqdm(evl_loader)):        \n",
    "        # use gpu if available\n",
    "        batch = [r.to(device) for r in batch]\n",
    "        seq, mask, labels = batch\n",
    "        with torch.no_grad():\n",
    "            batch_result = m(seq, mask)\n",
    "            rets = np.argmax(batch_result.detach().cpu(), axis = 1).tolist()\n",
    "            preds += rets\n",
    "            lbls += labels.tolist()\n",
    "    p, r, f, _ = precision_recall_fscore_support(lbls, preds, labels=eval_labels)\n",
    "    return {'precision': p[0], 'recall': r[0], 'f1': f[0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to train the model\n",
    "def train():\n",
    "    # dropout activates when in train mode \n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0\n",
    "    for step, batch in enumerate(tqdm(training_data_loader)):\n",
    "        \n",
    "        # use gpu if available\n",
    "        batch = [r.to(device) for r in batch]\n",
    "        \n",
    "        seq, mask, labels = batch\n",
    "        \n",
    "        # reset gradients \n",
    "        model.zero_grad()        \n",
    "\n",
    "        # get model outputs\n",
    "        outputs = model.forward(seq, mask)\n",
    "\n",
    "        # compute the loss between actual and predicted values\n",
    "        loss = cross_entropy(outputs, labels)\n",
    "\n",
    "        # accumulate loss\n",
    "        total_loss = total_loss + loss.item()\n",
    "\n",
    "        # calculate the gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # deal with the exploding gradient problem\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "    # calculate average loss\n",
    "    average_loss = total_loss / len(training_data_loader)\n",
    "    \n",
    "    ret = evaluate(model, dev_data_loader)\n",
    "  \n",
    "    return average_loss, ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = {'control': 0, 'case': 1}\n",
    "# initialise the model use pretrained bert_2 instance and the label numbers\n",
    "model = BERT_Text_Classifier(bert_2, class_num=len(categories))\n",
    "\n",
    "# push the model to GPU\n",
    "model = model.to(device)\n",
    "\n",
    "# define the optimizer\n",
    "# optimizer = AdamW(model.parameters(),\n",
    "#                   lr = learning_rate)\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "cross_entropy  = nn.NLLLoss() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:02<00:00, 25.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 99.70it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.385 dev performance, p:0.918, r:0.985, f1:0.950\n",
      "current best score is 0.950\n",
      "\n",
      " Epoch 2 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:02<00:00, 26.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 112.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.276 dev performance, p:0.918, r:0.985, f1:0.950\n",
      "\n",
      " Epoch 3 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:02<00:00, 26.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 84.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.283 dev performance, p:0.918, r:0.985, f1:0.950\n",
      "\n",
      " Epoch 4 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:02<00:00, 25.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 88.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.249 dev performance, p:0.919, r:1.000, f1:0.958\n",
      "current best score is 0.958\n",
      "\n",
      " Epoch 5 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:02<00:00, 25.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 86.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.261 dev performance, p:0.917, r:0.971, f1:0.943\n",
      "\n",
      " Epoch 6 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:02<00:00, 25.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 88.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.267 dev performance, p:0.918, r:0.985, f1:0.950\n",
      "\n",
      " Epoch 7 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:02<00:00, 25.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 111.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.232 dev performance, p:0.918, r:0.985, f1:0.950\n",
      "\n",
      " Epoch 8 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 30.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 110.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.242 dev performance, p:0.918, r:0.985, f1:0.950\n",
      "\n",
      " Epoch 9 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 30.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 108.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.206 dev performance, p:0.918, r:0.985, f1:0.950\n",
      "\n",
      " Epoch 10 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 29.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 111.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.212 dev performance, p:0.918, r:0.985, f1:0.950\n",
      "\n",
      " Epoch 11 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 30.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 111.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.189 dev performance, p:0.918, r:0.985, f1:0.950\n",
      "\n",
      " Epoch 12 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 30.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 110.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.249 dev performance, p:0.918, r:0.985, f1:0.950\n",
      "\n",
      " Epoch 13 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 30.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 112.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.199 dev performance, p:0.918, r:0.985, f1:0.950\n",
      "\n",
      " Epoch 14 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 30.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 110.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.192 dev performance, p:0.918, r:0.985, f1:0.950\n",
      "\n",
      " Epoch 15 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 30.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 111.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.213 dev performance, p:0.918, r:0.985, f1:0.950\n",
      "\n",
      " Epoch 16 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 30.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 108.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.253 dev performance, p:0.918, r:0.985, f1:0.950\n",
      "\n",
      " Epoch 17 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 29.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 110.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.170 dev performance, p:0.918, r:0.985, f1:0.950\n",
      "\n",
      " Epoch 18 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 30.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 110.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.156 dev performance, p:0.918, r:0.985, f1:0.950\n",
      "\n",
      " Epoch 19 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 30.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 111.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.152 dev performance, p:0.955, r:0.941, f1:0.948\n",
      "\n",
      " Epoch 20 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 29.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 110.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.286 dev performance, p:0.943, r:0.971, f1:0.957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#for each epoch\n",
    "\n",
    "best_model_state = None\n",
    "best_score = -1\n",
    "\n",
    "for epoch in range(epochs):\n",
    "     \n",
    "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs), flush=True)\n",
    "    #train model\n",
    "    train_loss, performance = train()\n",
    "    print('\\nTraining Loss: {:.3f}'.format(train_loss), \n",
    "          'dev performance, p:{precision:.3f}, r:{recall:.3f}, f1:{f1:.3f}'.format(**performance), flush=True)\n",
    "    if best_score < performance['f1']:\n",
    "        best_score = performance['f1']\n",
    "        best_model_state = copy.deepcopy(model.state_dict())\n",
    "        print('current best score is {0:.3f}'.format(best_score), flush=True)    \n",
    "\n",
    "ran = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = 'MEH_bluebert_initial.pt'\n",
    "torch.save(best_model_state, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not ran:\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    model_file = 'MEH_bluebert_initial.pt'\n",
    "\n",
    "    categories = {'control': 0, 'case': 1}\n",
    "    # initialise the model use pretrained bert instance and the label numbers\n",
    "    model = BERT_Text_Classifier(bert_2, class_num=len(categories))\n",
    "\n",
    "    model.load_state_dict(torch.load(model_file))\n",
    "    model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seq = test_seq.to(device)\n",
    "test_mask = test_mask.to(device)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:00<00:00, 98.60it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': 0.9493670886075949, 'recall': 1.0, 'f1': 0.974025974025974}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# dataLoader for test set\n",
    "# wrap tensors\n",
    "testing_data = TensorDataset(test_seq, test_mask, test_y)\n",
    "testing_data_loader = DataLoader(testing_data, batch_size=batch_size)     \n",
    "print(evaluate(model, testing_data_loader))\n",
    "# preds = np.argmax(preds.detach().cpu(), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.73      0.81        15\n",
      "           1       0.95      0.99      0.97        75\n",
      "\n",
      "    accuracy                           0.94        90\n",
      "   macro avg       0.93      0.86      0.89        90\n",
      "weighted avg       0.94      0.94      0.94        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predicting, so gradients\n",
    "with torch.no_grad():\n",
    "    preds = model(test_seq, test_mask)\n",
    "    \n",
    "preds = np.argmax(preds.detach().cpu(), axis = 1)\n",
    "print(classification_report(test_y, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_bluebert = confusion_matrix(test_y, preds, labels=[1,0])\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cm_bluebert, annot=True, ax = ax, cmap='Blues', fmt=\"d\")\n",
    "\n",
    "ax.set_title('Confusion Matrix of BlueBERT (MEH data)')\n",
    "\n",
    "ax.set_xlabel('Predicted Labels')\n",
    "ax.set_ylabel('True Labels')\n",
    "\n",
    "ax.xaxis.set_ticklabels(['FAKE', 'REAL'])\n",
    "ax.yaxis.set_ticklabels(['FAKE', 'REAL'])\n",
    "plt.savefig('Confusion_matrix_BlueBERT_meh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building sklearn text classifier...\n",
      "Building sklearn text classifier...\n",
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "Building sklearn text classifier...\n",
      "Loading bert-base-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 178, validation data size: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.893]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.00it/s, loss=0.482]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.323]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.217]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.06it/s, loss=0.203]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.07it/s, loss=0.171]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.201]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.169] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.95it/s, loss=0.184]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.06it/s, loss=0.188] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.194]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.155] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.129] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.08it/s, loss=0.143]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.136] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.131] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.101] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.00it/s, loss=0.105] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.0978]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.0995]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.95it/s, loss=0.0886]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.06it/s, loss=0.0749]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.0791]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.0688]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.00it/s, loss=0.0741] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.0651]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.0733]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.133] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.102] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.104]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.0886]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.0794]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.0789]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.1]   \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.086] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.00it/s, loss=0.0995]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.0807]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.0705]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.0566]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.06it/s, loss=0.0711]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.06it/s, loss=0.0616]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.06it/s, loss=0.0664]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.0634]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.0651]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.00it/s, loss=0.0633]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.07it/s, loss=0.0683]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.07it/s, loss=0.0616]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.0704] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.0719]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.0589]\n",
      "Predicting: 100%|██████████| 12/12 [00:01<00:00,  8.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building sklearn text classifier...\n",
      "Loading bert-base-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 178, validation data size: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.895]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.502]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.298]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.234]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.252]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.198] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.258]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.00it/s, loss=0.206] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.173]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.165]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.169]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.138] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.06it/s, loss=0.151]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.154] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.148] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.06it/s, loss=0.148] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.15]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.141] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.133]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.06it/s, loss=0.146] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.144] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.131] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.12] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.00it/s, loss=0.131] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.118] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.127] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.123] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.00it/s, loss=0.111]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.118]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.115] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.12]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.115] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.106]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.07it/s, loss=0.117] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.109] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.13] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.06it/s, loss=0.119] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.113] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.118] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.11] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.117] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.115]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.103]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.06it/s, loss=0.104]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.115]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.1]  \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.11]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.0992]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.124]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.109] \n",
      "Predicting: 100%|██████████| 12/12 [00:01<00:00,  8.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building sklearn text classifier...\n",
      "Loading bert-base-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 178, validation data size: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.06it/s, loss=0.902]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.07it/s, loss=0.513]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.34] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.252]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.28] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.207] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.218]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.235] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.06it/s, loss=0.181]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.211]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.18] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.07it/s, loss=0.162]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.16] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.152] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.154] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.149] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.07it/s, loss=0.143] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.06it/s, loss=0.125] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.95it/s, loss=0.116]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.108] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.142]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.07it/s, loss=0.108] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.116]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.129] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.11] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.122] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.114] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.116] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.12] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.119] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.89it/s, loss=0.113] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.113] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.112]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.111] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.106]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.06it/s, loss=0.11]  \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.118]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.121] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.109] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.07it/s, loss=0.111]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.00it/s, loss=0.123] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.113]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.106]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.113]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.105]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.105] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.107] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.0971]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.101] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.106]\n",
      "Predicting: 100%|██████████| 12/12 [00:01<00:00,  8.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building sklearn text classifier...\n",
      "Loading bert-base-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 178, validation data size: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.86] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.416]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.306]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.22] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.216]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.233]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.194]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.174]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.177]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.134] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.07it/s, loss=0.16] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.133] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.0865]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.0737]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.0813]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.00it/s, loss=0.0709]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.0707]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.09]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.0605]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.0958]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.06it/s, loss=0.0722]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.067] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.0743]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.95it/s, loss=0.0627]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.00it/s, loss=0.0658] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.0624]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.0729]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.0639]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.08it/s, loss=0.0685] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.0588]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.0638]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.0646]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.0571]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.0762]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.0679]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.0803]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.0693]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.0671]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.0558]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.0641]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.0571]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.07it/s, loss=0.0612]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.061] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.0599]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.0645]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.0612]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.0558]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.07it/s, loss=0.062]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.0685]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.0583]\n",
      "Predicting: 100%|██████████| 12/12 [00:01<00:00,  8.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building sklearn text classifier...\n",
      "Loading bert-base-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 178, validation data size: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.95it/s, loss=0.865]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.427]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.284]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.247]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.283]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.95it/s, loss=0.301]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.247]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.208] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.171]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.169]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.198]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.151] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.00it/s, loss=0.171]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.162] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.95it/s, loss=0.175]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.153]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.227]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.148] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.124] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.147] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.138] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.124] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.127]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.135] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.124] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.127] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.125] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.95it/s, loss=0.111]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.115] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.107]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.123] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.105] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.102]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.116]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.105]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.121] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.119] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.109] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.109] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.104] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.117] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.111]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.103]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.103]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.114] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.098]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.101] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.0987]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.131] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.113] \n",
      "Predicting: 100%|██████████| 12/12 [00:01<00:00,  8.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building sklearn text classifier...\n",
      "Loading bert-base-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 178, validation data size: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.00it/s, loss=0.875]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.447]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.302]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.258]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.463]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.256]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.196]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.90it/s, loss=0.214] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.161]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.94it/s, loss=0.172]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.00it/s, loss=0.129]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.186]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.172] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.161] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.159] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.15] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.00it/s, loss=0.17] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.127] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.134]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.124] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.147] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.125] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.132]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.138]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.125]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.131] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.95it/s, loss=0.119] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.94it/s, loss=0.132]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.124] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.128] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.00it/s, loss=0.139] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.127] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.124]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.133] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.119]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.121]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.128]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.128] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.119] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.122]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.14]  \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.124]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.118]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.122]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.124]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.117] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.12] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.119]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.118] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.12] \n",
      "Predicting: 100%|██████████| 12/12 [00:01<00:00,  8.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building sklearn text classifier...\n",
      "Loading bert-base-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 178, validation data size: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.924]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.608]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.367]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.288]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.221]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.246]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.209]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.178]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.183]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.165] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.189]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.165] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.183] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.152] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.164]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.155]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.14] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.125] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.11] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.112] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.00it/s, loss=0.081] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.0825]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.0859]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.94it/s, loss=0.0796]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.94it/s, loss=0.0752]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.0637]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.0785]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.0736]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.0724]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.0647]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.066] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.0834]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.94it/s, loss=0.0608]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.0829]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.0702]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.0812]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.0817]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.0726]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.94it/s, loss=0.0648]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.0688]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.0654]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.0665]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.0663]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.0685]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.0669]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.0671]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.0589]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.0633] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.0772]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.0635]\n",
      "Predicting: 100%|██████████| 12/12 [00:01<00:00,  7.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building sklearn text classifier...\n",
      "Loading bert-base-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 178, validation data size: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.91it/s, loss=0.923]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.609]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.354]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.264]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.234]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.21]  \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.95it/s, loss=0.247]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.215]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.90it/s, loss=0.204]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.242]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.233]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.188]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.238]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.234] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.94it/s, loss=0.209]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.202]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.194] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.166] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.152]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.164] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.94it/s, loss=0.143] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.00it/s, loss=0.136] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.129]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.132]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.119]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.126] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.118]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.116]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.126]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.114] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.95it/s, loss=0.116] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.112]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.00it/s, loss=0.101]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.117] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.109]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.132]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.91it/s, loss=0.118] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.107] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.123] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.117]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.91it/s, loss=0.114] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.113]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.1]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.00it/s, loss=0.105]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.91it/s, loss=0.114] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.0962]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.108] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.95it/s, loss=0.105]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.109] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.94it/s, loss=0.108] \n",
      "Predicting: 100%|██████████| 12/12 [00:01<00:00,  7.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building sklearn text classifier...\n",
      "Loading bert-base-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 178, validation data size: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.929]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.631]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.90it/s, loss=0.4]  \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.295]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.94it/s, loss=0.258]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.91it/s, loss=0.228] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.235]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.253]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.213]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.221]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.215]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.91it/s, loss=0.223]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.217]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.232]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.221]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.218]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.228]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.88it/s, loss=0.192]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.188]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.90it/s, loss=0.162] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.191]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.149]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.151]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.144]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.152]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.91it/s, loss=0.169] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.128] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.131] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.131]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.133] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.90it/s, loss=0.113] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.94it/s, loss=0.112] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.00it/s, loss=0.111]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.108] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.91it/s, loss=0.113]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.111]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.112] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.123] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.117] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.94it/s, loss=0.122]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.12]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.128] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.105]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.109]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.111]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.111] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.111]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.95it/s, loss=0.111]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.115] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.114]\n",
      "Predicting: 100%|██████████| 12/12 [00:01<00:00,  8.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building sklearn text classifier...\n",
      "Loading bert-base-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 178, validation data size: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.913]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.547]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.346]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.90it/s, loss=0.267]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.205]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.191]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.202]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.196]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.177]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.166] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.19] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.159] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.171] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.138] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.134]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.126] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.0933]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.106] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.0662]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.00it/s, loss=0.0888]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.0676]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.0644]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.0702]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.0797]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.00it/s, loss=0.0734] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.94it/s, loss=0.0662]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.0789]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.0677]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.0694]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.0639]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.0704]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.0701]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.0614]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.0935]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.071] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.0937]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.91it/s, loss=0.0731]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.94it/s, loss=0.0714] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.0622]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.0682]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.0649]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.0638]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.0616]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.00it/s, loss=0.069] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.94it/s, loss=0.0632]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.95it/s, loss=0.0669]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.0623]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.95it/s, loss=0.0664] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.90it/s, loss=0.0755]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.95it/s, loss=0.0572]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.0863]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.0625]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.0622]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.0675]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.0598]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.94it/s, loss=0.0584]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.0812]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.0696]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.0625]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.0598]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.0598]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.0642]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.0561]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.067] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.0635]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.0654]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.0627]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.061]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.075] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.94it/s, loss=0.0637]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.064]  \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.0632]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.0543]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.0637] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.0568]\n",
      "Predicting: 100%|██████████| 12/12 [00:01<00:00,  7.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building sklearn text classifier...\n",
      "Loading bert-base-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 178, validation data size: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.913]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.566]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.335]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.95it/s, loss=0.251]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.27] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.239] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.265]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.232]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.235]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.221]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.218]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.182]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.176]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.178] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.95it/s, loss=0.159] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.155] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.165] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.142] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.125]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.122] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.95it/s, loss=0.119] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.111] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.118]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.115] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.105] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.86it/s, loss=0.116] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.118] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.106]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.116]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.88it/s, loss=0.118] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.11]  \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.86it/s, loss=0.106] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.0992]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.94it/s, loss=0.112] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.105]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.88it/s, loss=0.122] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.114] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.107] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.103] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.94it/s, loss=0.105] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.91it/s, loss=0.109] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.95it/s, loss=0.11]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.0985]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.105]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.114] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.0959]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.94it/s, loss=0.102] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.0979]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.112] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.88it/s, loss=0.101] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.115] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.94it/s, loss=0.111] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.108]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.95it/s, loss=0.12]  \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.95it/s, loss=0.108] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.11] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.89it/s, loss=0.123] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.90it/s, loss=0.112]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.113] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.106]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.101]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.94it/s, loss=0.102]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.101] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.105] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.94it/s, loss=0.115] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.104] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.95it/s, loss=0.0966]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.95it/s, loss=0.0991]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.115] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.0971]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.91it/s, loss=0.113] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.94it/s, loss=0.108] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.91it/s, loss=0.122] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.0999]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.108]\n",
      "Predicting: 100%|██████████| 12/12 [00:01<00:00,  7.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building sklearn text classifier...\n",
      "Loading bert-base-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 178, validation data size: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.92] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.90it/s, loss=0.581]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.383]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.278]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.91it/s, loss=0.254]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.91it/s, loss=0.233] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.91it/s, loss=0.233]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.216]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.161]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.90it/s, loss=0.164] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.91it/s, loss=0.16] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.95it/s, loss=0.137]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.172]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.94it/s, loss=0.222]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.195] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.91it/s, loss=0.191]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.191]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.164]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.136]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.125] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.151] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.95it/s, loss=0.127] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.91it/s, loss=0.131] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.141] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.115] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.133] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.95it/s, loss=0.12]  \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.115]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.124] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.12]  \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.94it/s, loss=0.113] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.91it/s, loss=0.116] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.91it/s, loss=0.114]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.87it/s, loss=0.107]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.94it/s, loss=0.115]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.119]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.117] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.112] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.91it/s, loss=0.12]  \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.87it/s, loss=0.109]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.115] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.95it/s, loss=0.112] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.89it/s, loss=0.103]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.94it/s, loss=0.11] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.94it/s, loss=0.111]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.91it/s, loss=0.103] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.90it/s, loss=0.101] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.94it/s, loss=0.11] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.94it/s, loss=0.105] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.108]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.94it/s, loss=0.104] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.94it/s, loss=0.118] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.107] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.123]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.94it/s, loss=0.113] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.87it/s, loss=0.119] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.91it/s, loss=0.113] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.94it/s, loss=0.103] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.91it/s, loss=0.112] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.90it/s, loss=0.112]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.88it/s, loss=0.107]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.89it/s, loss=0.108]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.098] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.90it/s, loss=0.109] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.87it/s, loss=0.112] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.89it/s, loss=0.103] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.0968]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.102] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.119] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.89it/s, loss=0.0989]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.94it/s, loss=0.114] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.94it/s, loss=0.112] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.86it/s, loss=0.128] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.106]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.90it/s, loss=0.102]\n",
      "Predicting: 100%|██████████| 12/12 [00:01<00:00,  7.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building sklearn text classifier...\n",
      "Loading bert-base-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 178, validation data size: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.90it/s, loss=0.893]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.94it/s, loss=0.482]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.90it/s, loss=0.323]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.217]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.203]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.171]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.215]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.91it/s, loss=0.16]  \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.202]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.187] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.203]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.147] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.136] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.103] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.111]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.91it/s, loss=0.086] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.0763]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.94it/s, loss=0.0938]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.0736]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.94it/s, loss=0.107] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.90it/s, loss=0.107] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.0804]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.0799]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.94it/s, loss=0.0702]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.94it/s, loss=0.0755] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.0703]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.88it/s, loss=0.0864]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.91it/s, loss=0.0648]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.95it/s, loss=0.0716] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.85it/s, loss=0.0614]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.89it/s, loss=0.0695]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.0638]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.95it/s, loss=0.0594]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.89it/s, loss=0.088] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.91it/s, loss=0.0679]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.85it/s, loss=0.0836]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.95it/s, loss=0.0723]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.0659]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.91it/s, loss=0.0604]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.0658]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.94it/s, loss=0.0613]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.89it/s, loss=0.0634]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.0574]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.87it/s, loss=0.0613]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.91it/s, loss=0.0653]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.0633]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.91it/s, loss=0.059] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.0595] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.91it/s, loss=0.0688]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.058] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.87it/s, loss=0.0832]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.91it/s, loss=0.0649]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.061] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.90it/s, loss=0.0755]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.88it/s, loss=0.0581]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.0571]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.91it/s, loss=0.0778]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.90it/s, loss=0.0639]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.91it/s, loss=0.0639]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.0575]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.94it/s, loss=0.0621]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.0606]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.0569]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.95it/s, loss=0.0645]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.91it/s, loss=0.0578]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.90it/s, loss=0.0565]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.89it/s, loss=0.0591]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.91it/s, loss=0.0543] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.88it/s, loss=0.0734]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.0591]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.87it/s, loss=0.0607]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.0635]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.87it/s, loss=0.0596]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.87it/s, loss=0.061]  \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.0598]\n",
      "Predicting: 100%|██████████| 12/12 [00:01<00:00,  7.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building sklearn text classifier...\n",
      "Loading bert-base-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 178, validation data size: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.94it/s, loss=0.895]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.91it/s, loss=0.502]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.298]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.95it/s, loss=0.234]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.90it/s, loss=0.252]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.198] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.265]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.88it/s, loss=0.205] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.86it/s, loss=0.183]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.187]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.91it/s, loss=0.191]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.95it/s, loss=0.161] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.91it/s, loss=0.167]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.89it/s, loss=0.162] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.86it/s, loss=0.159] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.89it/s, loss=0.149] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.148] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.135] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.129] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.91it/s, loss=0.147] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.91it/s, loss=0.13]  \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.94it/s, loss=0.132] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.115]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.91it/s, loss=0.128] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.90it/s, loss=0.116] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.123] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.122] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.90it/s, loss=0.105]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.107]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.90it/s, loss=0.112] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.94it/s, loss=0.12]  \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.11]  \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.107]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.112] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.105]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.89it/s, loss=0.122] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.95it/s, loss=0.125] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.89it/s, loss=0.113] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.91it/s, loss=0.114] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.112]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.124] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.91it/s, loss=0.121]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.111]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.94it/s, loss=0.108]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.88it/s, loss=0.125] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.88it/s, loss=0.0973]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.91it/s, loss=0.107] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.90it/s, loss=0.101]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.90it/s, loss=0.114] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.91it/s, loss=0.104] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.94it/s, loss=0.114] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.88it/s, loss=0.113] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.121]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.91it/s, loss=0.111] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.88it/s, loss=0.113] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.109]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.132] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.87it/s, loss=0.106] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.91it/s, loss=0.118] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.104]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.94it/s, loss=0.106]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.102]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.89it/s, loss=0.103] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.90it/s, loss=0.108] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.0971]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.85it/s, loss=0.103] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.90it/s, loss=0.0989]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.87it/s, loss=0.103]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.84it/s, loss=0.119] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.94it/s, loss=0.102]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.94it/s, loss=0.111] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.114]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.90it/s, loss=0.118] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.105] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.0964]\n",
      "Predicting: 100%|██████████| 12/12 [00:01<00:00,  7.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building sklearn text classifier...\n",
      "Loading bert-base-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 178, validation data size: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.902]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.94it/s, loss=0.513]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.34] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.252]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.28] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.84it/s, loss=0.208] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.223]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.235]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.88it/s, loss=0.158]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.88it/s, loss=0.16]  \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.138]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.127]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.178]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.159] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.87it/s, loss=0.151] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.90it/s, loss=0.176]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.89it/s, loss=0.154]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.86it/s, loss=0.129] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.117]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.114] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.146]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.90it/s, loss=0.116] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.117] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.87it/s, loss=0.132] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.86it/s, loss=0.118]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.118] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.86it/s, loss=0.113] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.90it/s, loss=0.125]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.119] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.90it/s, loss=0.123] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.115] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.118] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.91it/s, loss=0.11] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.90it/s, loss=0.11]  \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.116]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.118]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.89it/s, loss=0.108]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.12]  \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.95it/s, loss=0.11]  \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.116]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.95it/s, loss=0.122] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.91it/s, loss=0.109] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.105]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.95it/s, loss=0.111]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.86it/s, loss=0.104]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.84it/s, loss=0.104] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.95it/s, loss=0.105] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.87it/s, loss=0.0996]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.0998]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.108]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.87it/s, loss=0.105] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.94it/s, loss=0.128] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.87it/s, loss=0.109] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.90it/s, loss=0.118] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.111] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.91it/s, loss=0.113] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.87it/s, loss=0.114] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.109] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.91it/s, loss=0.112] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.113]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.108]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.87it/s, loss=0.108]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.101] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.104] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.94it/s, loss=0.112] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.107]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.102]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.101] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.94it/s, loss=0.115]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.91it/s, loss=0.0989]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.111] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.116] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.88it/s, loss=0.122] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.94it/s, loss=0.108] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.94it/s, loss=0.11]  \n",
      "Predicting: 100%|██████████| 12/12 [00:01<00:00,  7.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building sklearn text classifier...\n",
      "Loading bert-base-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 178, validation data size: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.936]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.686]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.412]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.86it/s, loss=0.315]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.91it/s, loss=0.254]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.88it/s, loss=0.24] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.21] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.91it/s, loss=0.212]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.91it/s, loss=0.226]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.22] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.218]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.90it/s, loss=0.193] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.88it/s, loss=0.201]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.177]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.86it/s, loss=0.184]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.89it/s, loss=0.178]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.89it/s, loss=0.154]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.174]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.88it/s, loss=0.158]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.164]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.94it/s, loss=0.119] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.116] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.90it/s, loss=0.0848]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.0902]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.0822]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.91it/s, loss=0.0828]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.88it/s, loss=0.0812]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.91it/s, loss=0.0733]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.0898] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.87it/s, loss=0.105] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.89it/s, loss=0.0879]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.89it/s, loss=0.0762]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.0726]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.91it/s, loss=0.095] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.94it/s, loss=0.0783]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.1]   \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.94it/s, loss=0.0797]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.89it/s, loss=0.082] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.066] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.91it/s, loss=0.0743]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.91it/s, loss=0.0764]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.88it/s, loss=0.0683]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.83it/s, loss=0.0675]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.0701]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.067] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.90it/s, loss=0.0684]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.94it/s, loss=0.0669]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.90it/s, loss=0.0649]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.88it/s, loss=0.0808]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.86it/s, loss=0.064] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.0828]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.0671]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.95it/s, loss=0.0637]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.07]  \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.82it/s, loss=0.0595]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.88it/s, loss=0.0605]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.86it/s, loss=0.0842]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.0772]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.86it/s, loss=0.0673]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.0635]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.0538]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.063] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.0639]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.86it/s, loss=0.0674]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.85it/s, loss=0.0703]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.0646]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.89it/s, loss=0.0713]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.88it/s, loss=0.0633] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.90it/s, loss=0.0865]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.94it/s, loss=0.0672]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.89it/s, loss=0.067]  \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.0735]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.91it/s, loss=0.0591]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.84it/s, loss=0.0688]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.91it/s, loss=0.0609]\n",
      "Predicting: 100%|██████████| 12/12 [00:01<00:00,  7.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building sklearn text classifier...\n",
      "Loading bert-base-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 178, validation data size: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.934]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.697]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.405]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.298]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.287]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.216]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.259]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.224]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.00it/s, loss=0.199]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.22] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.217]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.181]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.218]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.215] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.209]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.208]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.196] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.171] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.17] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.177] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.174]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.149]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.149]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.148]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.135]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.07it/s, loss=0.139] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.126]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.12] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.143]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.12]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.13]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.126]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.107]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.117]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.118]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.13] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.06it/s, loss=0.126] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.11]  \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.112] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.111]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.07it/s, loss=0.117] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.117]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.1]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.107]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.06it/s, loss=0.12]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.06it/s, loss=0.0953]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.11]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.107]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.116] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.108] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.119] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.113] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.111]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.115] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.105] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.103]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.131] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.108] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.07it/s, loss=0.116] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.11] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.108]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.06it/s, loss=0.108]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.107] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.115] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.00it/s, loss=0.111] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.106] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.108]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.101] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.07it/s, loss=0.116] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.0983]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.121] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.11]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.119] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.104] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.101]\n",
      "Predicting: 100%|██████████| 12/12 [00:01<00:00,  8.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building sklearn text classifier...\n",
      "Loading bert-base-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 178, validation data size: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.941]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.713]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.458]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.313]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.298]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.233]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.238]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.262]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.06it/s, loss=0.216]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.06it/s, loss=0.224]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.00it/s, loss=0.215]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.219]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.214]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.231]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.211]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.197]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.208]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.172]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.169]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.148] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.175]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.14] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.149]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.158]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.129]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.00it/s, loss=0.146] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.133]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.123]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.143]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.132] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.135] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.118]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.115]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.12]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.109]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.115] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.125]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.122] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.118] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.06it/s, loss=0.112]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.118] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.113] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.105]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.06it/s, loss=0.114]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.104]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.115] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.06it/s, loss=0.109] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.108]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.08it/s, loss=0.106] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.104] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.105] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.07it/s, loss=0.127] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.109] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.123]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.113] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.112] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.117]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.105] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.07it/s, loss=0.114] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.118]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.107]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.11] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.06it/s, loss=0.104] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.104] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.113] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.11] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.0952]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.108] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.115] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.104]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.114] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.06it/s, loss=0.131]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.117] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.115] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.00it/s, loss=0.108] \n",
      "Predicting: 100%|██████████| 12/12 [00:01<00:00,  8.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building sklearn text classifier...\n",
      "Loading bert-base-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 178, validation data size: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.924]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.608]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.367]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.288]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.221]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.241]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.247]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.198]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.177]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.163] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.205]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.131] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.0991]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.94it/s, loss=0.117]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.06it/s, loss=0.102]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.11]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.103] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.105] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.0959]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.113] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.0909]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.07it/s, loss=0.0838]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.0756]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.0761]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.0727] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.0712]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.082] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.0687]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.0754] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.0644]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.0691]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.0683]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.0657]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.0841]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.0677]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.0825]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.0734]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.0707] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.00it/s, loss=0.0637]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.0693]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.0635]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.0676]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.0644]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.0639]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.0652]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.0643]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.0626]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.0658] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.0799]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.0589]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.0821]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.0614]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.0679]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.0742]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.06it/s, loss=0.0632]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.06it/s, loss=0.0598]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.06it/s, loss=0.0784]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.0645]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.063] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.0626]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.0605]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.0662]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.0595]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.0659]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.0595]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.0609]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.07it/s, loss=0.0616]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.0574]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.0742]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.0611]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.0612] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.0611]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.0612]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.0609] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.0605]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.0752]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.0624]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.0794]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.0695]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.0561]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.0577] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.0627]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.0598]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.0599]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.058] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.0634]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.064] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.00it/s, loss=0.0644]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.0766]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.0635]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.00it/s, loss=0.0578] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.06it/s, loss=0.0598] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.0624]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.058] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.066] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.0643]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.059] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.0596]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.0629]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.057] \n",
      "Predicting: 100%|██████████| 12/12 [00:01<00:00,  8.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building sklearn text classifier...\n",
      "Loading bert-base-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 178, validation data size: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.923]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.609]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.354]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.264]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.234]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.21]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.248]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.00it/s, loss=0.215]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.225]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.241]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.243]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.196]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.00it/s, loss=0.203]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.197] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.179]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.156]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.162]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.139] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.123]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.134] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.00it/s, loss=0.134] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.128] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.127]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.118] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.114] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.114] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.00it/s, loss=0.107] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.115]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.115] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.00it/s, loss=0.116]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.107] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.104] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.00it/s, loss=0.107]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.111] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.112]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.95it/s, loss=0.137]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.119] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.0982]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.107] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.126]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.00it/s, loss=0.119] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.117]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.106]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.109] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.118] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.103]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.94it/s, loss=0.107] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.104]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.118]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.109] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.00it/s, loss=0.118] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.115] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.106]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.113] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.111] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.104]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.126] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.101] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.128] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.00it/s, loss=0.109]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.0979]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.0982]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.114] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.106] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.113] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.102] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.0964]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.00it/s, loss=0.0931]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.118] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.098]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.115] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.109] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.123] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.103] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.101] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.127] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.111] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.122] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.102] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.106]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.103] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.0983]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.0936]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.111] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.107] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.101]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.122] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.108] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.111] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.107] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.111] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.103] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.0988]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.114] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.106] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.108] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.0972]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.11] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.115] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.00it/s, loss=0.114] \n",
      "Predicting: 100%|██████████| 12/12 [00:01<00:00,  8.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building sklearn text classifier...\n",
      "Loading bert-base-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 178, validation data size: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.00it/s, loss=0.929]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.631]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.4]  \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.295]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.95it/s, loss=0.258]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.228] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.235]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.252]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.211]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.237]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.00it/s, loss=0.229]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.216]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.219]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.213]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.00it/s, loss=0.178] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.00it/s, loss=0.171]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.158]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.133] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.125]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.12]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.135]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.103] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.141]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.138]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.116]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.00it/s, loss=0.12]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.00it/s, loss=0.109] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.112]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.113]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.115] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.108] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.117] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.104] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.105] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.102]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.114]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.00it/s, loss=0.113] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.117] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.111] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.117]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.00it/s, loss=0.117] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.112] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.104]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.102]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.102]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.103] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.108] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.103]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.113] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.107]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.106] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.126] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.107] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.116] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.107] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.116] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.111] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.94it/s, loss=0.106]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.117] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.114]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.104]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.109]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.0994]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.90it/s, loss=0.102] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.115] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.107] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.0979]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.099] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.113] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.101]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.115] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.116] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.124] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.111]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.111] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.119] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.00it/s, loss=0.111] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.11]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.00it/s, loss=0.114] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.103]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.105] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.103] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.1]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.103] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.105] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.108] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.119] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.109]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.106] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.106]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.109] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.106] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.95it/s, loss=0.104] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.118]  \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.106]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.106] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.101] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.109] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.112] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.112] \n",
      "Predicting: 100%|██████████| 12/12 [00:01<00:00,  8.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building sklearn text classifier...\n",
      "Loading bert-base-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 178, validation data size: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.908]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.522]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.335]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.244]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.216]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.173]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.187]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.173] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.166]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.156] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.175]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.123] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.146]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.108] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.0838]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.097] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.00it/s, loss=0.0698]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.128] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.0767]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.0809]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.0656]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.0584]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.0815]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.0899]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.06it/s, loss=0.0744]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.0684]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.0773]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.00it/s, loss=0.0687]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.0709]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.00it/s, loss=0.0605]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.0655]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.0673]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.0615]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.143] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.0917]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.0857]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.0736]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.00it/s, loss=0.0686]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.0629]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.0679]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.0577]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.0621]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.95it/s, loss=0.0588]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.90it/s, loss=0.0562]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.0602]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.0647]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.0633]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.0653] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.081] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.0616]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.0785]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.0566]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.063] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.0791]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.0622]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.0562]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.0806]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.94it/s, loss=0.0643]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.0635]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.00it/s, loss=0.0624]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.0556]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.0684]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.0568]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.065] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.061] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.0602]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.0602]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.0576] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.0694]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.0632]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.0654] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.0628]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.94it/s, loss=0.0537]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.0622] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.0595]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.94it/s, loss=0.0796]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.0631]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.0786]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.0629]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.00it/s, loss=0.0552]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.0572]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.0608]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.0587]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.00it/s, loss=0.0559]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.0628]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.0603]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.0651]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.0645]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.95it/s, loss=0.0774]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.0653]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.95it/s, loss=0.0528] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.06it/s, loss=0.0602] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.062] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.0536]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.00it/s, loss=0.0627]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.0641]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.0558]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.0555]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.0621]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.00it/s, loss=0.0577]\n",
      "Predicting: 100%|██████████| 12/12 [00:01<00:00,  8.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building sklearn text classifier...\n",
      "Loading bert-base-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 178, validation data size: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.908]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.54] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.95it/s, loss=0.325]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.249]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.23] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.221] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.251]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.212]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.198]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.201]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.2]  \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.152] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.173]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.17]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.165] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.146] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.144] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.153] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.94it/s, loss=0.138] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.94it/s, loss=0.126] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.137] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.126] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.128]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.119] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.113]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.125] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.103]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.105]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.111]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.117] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.112] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.106]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.0997]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.112] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.94it/s, loss=0.106]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.118] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.111] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.111] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.114] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.11]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.11]  \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.113]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.0981]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.104]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.94it/s, loss=0.117] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.0975]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.102] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.107]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.108] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.105] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.113] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.116] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.108]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.122]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.109] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.11] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.129] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.114] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.117] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.107]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.102]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.1]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.1]   \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.109] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.106] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.106] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.0959]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.102]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.116] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.0985]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.119] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.95it/s, loss=0.109] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.94it/s, loss=0.121] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.0998]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.106]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.122] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.101] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.122] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.108] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.107] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.0988]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.105]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.103]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.105] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.11]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.106]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.112] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.107] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.111] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.102] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.106] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.00it/s, loss=0.107] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.104] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.109] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.102] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.102]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.0992]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.102]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.103] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.106] \n",
      "Predicting: 100%|██████████| 12/12 [00:01<00:00,  8.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building sklearn text classifier...\n",
      "Loading bert-base-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 178, validation data size: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.06it/s, loss=0.915]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.565]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.354]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.276]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.245]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.239] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.23] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.243] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.209]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.205]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.16] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.145]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.162]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.15]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.164] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.158] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.17] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.132] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.125]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.116] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.131] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.131]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.135]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.138]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.114]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.131] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.115] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.122] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.123]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.129] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.121] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.119] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.114]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.108] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.105]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.112] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.108] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.94it/s, loss=0.116] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.107] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.113]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.132] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.119] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.07it/s, loss=0.105]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.106]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.106]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.101] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.94it/s, loss=0.109] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.101]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.105] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.00it/s, loss=0.107]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.107] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.121] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.107] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.123] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.95it/s, loss=0.112] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.117] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.113] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.109] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.116] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.113]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.109]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.112]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.0996]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.106] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.111] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.107] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.0985]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.0986]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.112] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.102]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.115] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.115] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.127] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.107] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.106] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.00it/s, loss=0.112] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.89it/s, loss=0.115] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.113] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.104] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.1]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.0999]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.103] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.95it/s, loss=0.102]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.104] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.106]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.111]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.114] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.106]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.104] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.104]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.109] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.109] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.00it/s, loss=0.103]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.115] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.1]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.11]  \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.101] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.108] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.115] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.06it/s, loss=0.11]  \n",
      "Predicting: 100%|██████████| 12/12 [00:01<00:00,  8.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building sklearn text classifier...\n",
      "Loading bert-base-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 178, validation data size: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.943]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.95it/s, loss=0.746]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.463]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.339]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.259]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.227]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.202]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.177] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.175]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.06it/s, loss=0.168]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.227]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.95it/s, loss=0.186] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.185] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.92it/s, loss=0.156] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.181]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.161]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.15] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.138]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.108] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.119] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.1]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.0892]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.0816]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.0762]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.0703]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.0716]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.078] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.95it/s, loss=0.0703]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.0758]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.00it/s, loss=0.0688]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.0634]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.0711]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.0587]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.0843]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.0745]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.0826]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.0713]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.0798]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.0667]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.0673]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.06]  \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.0614]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.00it/s, loss=0.0605]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.063] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.0668]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.0686]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.0585]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.064]  \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.94it/s, loss=0.0767]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.00it/s, loss=0.059] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.083] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.95it/s, loss=0.0644]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.0589]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.0672]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.0541]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.0633]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.084] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.0658]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.0649]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.0621]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.0599]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.00it/s, loss=0.068] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.0628]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.00it/s, loss=0.0597]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.0598]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.064] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.0614]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.0566] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.0721]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.0652]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.07it/s, loss=0.0645] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.0629]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.0588]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.0631]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.0609]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.0781]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.0653]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.0784]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.0657]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.0571]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.0572] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.0596]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.0612]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.95it/s, loss=0.0571]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.0608]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.0607]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.0633]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.0656]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.0771]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.064] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.0569] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.064]  \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.0621]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.0568]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.91it/s, loss=0.0677]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.0658]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.0572]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.0598]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.0667]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.0604]\n",
      "Predicting: 100%|██████████| 12/12 [00:01<00:00,  8.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building sklearn text classifier...\n",
      "Loading bert-base-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 178, validation data size: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.94] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.747]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.454]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.95it/s, loss=0.323]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.287]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.236]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.251]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.23] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.209]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.213]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.224]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.192]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.225]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.232] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.95it/s, loss=0.214]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.00it/s, loss=0.216]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.00it/s, loss=0.208] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.194] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.186]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.00it/s, loss=0.183]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.193]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.165]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.00it/s, loss=0.17] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.95it/s, loss=0.16] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.142]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.15] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.136]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.94it/s, loss=0.121]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.156]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.118] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.126] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.115]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.106]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.125]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.114]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.129] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.124] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.113] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.115] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.115]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.116] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.12] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.101]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.105] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.12] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.95it/s, loss=0.0988]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.00it/s, loss=0.106] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.111]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.124]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.114] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.121] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.121] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.11] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.124]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.116] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.105]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.125] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.115] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.114] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.105]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.102]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.103] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.105] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.102] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.95it/s, loss=0.12]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.104] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.95it/s, loss=0.0983]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.104] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.115] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.101]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.118] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.115] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.126] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.109]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.106]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.124] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.105] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.119] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.111] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.105] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.0952]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.104]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.1]  \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.109] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.115] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.111]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.116] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.103] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.117] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.102] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.94it/s, loss=0.111] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.106] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.94it/s, loss=0.103] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.116] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.108]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.103]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.102] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.106]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.1]   \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.116] \n",
      "Predicting: 100%|██████████| 12/12 [00:01<00:00,  8.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building sklearn text classifier...\n",
      "Loading bert-base-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 178, validation data size: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.947]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.754]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.00it/s, loss=0.504]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.333]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.302]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.248]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.248]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.252]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.208]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.21] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.94it/s, loss=0.209]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.207]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.00it/s, loss=0.214]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.237]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.216] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.213]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.215]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.186]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.00it/s, loss=0.184]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.16]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.184]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.15] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.159]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.06it/s, loss=0.161]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.144]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.151] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.141] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.131]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.94it/s, loss=0.129]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.131] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.123] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.00it/s, loss=0.113] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.104]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.117] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.94it/s, loss=0.106]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.129] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.118]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.14]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.118] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.126]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.125] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.117] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.0963]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.111]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.108]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.112] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.117]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.11] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.11]  \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.112]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.107]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.135] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.11]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.12] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.114] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.114] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.118] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.105] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.122]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.122]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=0.108]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.111]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.104] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.102] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.121] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.1]   \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.0972]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.102] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.115] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.00it/s, loss=0.101]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.118] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.124]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.128] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.127] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.90it/s, loss=0.109] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.115] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=0.112] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.111] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.00it/s, loss=0.116] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.113]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.03it/s, loss=0.105] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.11] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.0991]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.11]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.106] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.11]  \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.117] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.115]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.00it/s, loss=0.109] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.106]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.113] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.105] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=0.101]\n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.123] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  2.00it/s, loss=0.108]\n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=0.104] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.11]  \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.111] \n",
      "Training  : 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.115] \n",
      "Training  : 100%|██████████| 6/6 [00:03<00:00,  1.95it/s, loss=0.115] \n",
      "Predicting: 100%|██████████| 12/12 [00:01<00:00,  8.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building sklearn text classifier...\n",
      "Building sklearn text classifier...\n",
      "Loading bert-base-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 267, validation data size: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.28it/s, loss=0.781]\n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.32it/s, loss=0.346]\n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.32it/s, loss=0.259]\n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.30it/s, loss=0.211]\n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.32it/s, loss=0.222]\n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.30it/s, loss=0.195]\n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.31it/s, loss=0.194]\n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.30it/s, loss=0.179]\n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.32it/s, loss=0.156]\n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.33it/s, loss=0.145] \n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.29it/s, loss=0.204] \n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.31it/s, loss=0.189]\n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.31it/s, loss=0.162] \n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.31it/s, loss=0.181]\n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.32it/s, loss=0.176]\n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.33it/s, loss=0.149]\n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.33it/s, loss=0.145] \n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.32it/s, loss=0.15]  \n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.29it/s, loss=0.121]\n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.28it/s, loss=0.145] \n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.30it/s, loss=0.12] \n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.31it/s, loss=0.114] \n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.30it/s, loss=0.118] \n",
      "Training  : 100%|██████████| 9/9 [00:04<00:00,  2.21it/s, loss=0.115]\n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.30it/s, loss=0.115] \n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.29it/s, loss=0.162] \n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.31it/s, loss=0.116]\n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.33it/s, loss=0.116] \n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.32it/s, loss=0.102] \n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.32it/s, loss=0.106] \n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.32it/s, loss=0.11]  \n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.32it/s, loss=0.137] \n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.31it/s, loss=0.122] \n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.29it/s, loss=0.117] \n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.32it/s, loss=0.11] \n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.31it/s, loss=0.115] \n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.31it/s, loss=0.102] \n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.31it/s, loss=0.125] \n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.31it/s, loss=0.0942]\n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.28it/s, loss=0.0937]\n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.32it/s, loss=0.101] \n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.32it/s, loss=0.0925]\n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.31it/s, loss=0.0965]\n",
      "Training  : 100%|██████████| 9/9 [00:04<00:00,  2.25it/s, loss=0.0984]\n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.32it/s, loss=0.102] \n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.30it/s, loss=0.107] \n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.29it/s, loss=0.0963]\n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.29it/s, loss=0.0927]\n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.31it/s, loss=0.0959]\n",
      "Training  : 100%|██████████| 9/9 [00:03<00:00,  2.29it/s, loss=0.089] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=BertClassifier(max_seq_length=64, validation_fraction=0),\n",
       "             param_grid={'epochs': [50, 75, 100],\n",
       "                         'learning_rate': [2e-05, 3e-05, 1e-05]},\n",
       "             scoring='accuracy', verbose=True)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%time\n",
    "# from bert import run_classifier\n",
    "params = {'epochs':[50, 75, 100], 'learning_rate':[2e-5, 3e-5, 1e-5]}\n",
    "\n",
    "# wrap classifier/regressor in GridSearchCV\n",
    "clf_bert = GridSearchCV(BertClassifier(validation_fraction=0, max_seq_length=64), \n",
    "                   params,\n",
    "                   cv=3,\n",
    "                   scoring='accuracy',\n",
    "                   verbose=True)\n",
    "\n",
    "# fit gridsearch \n",
    "clf_bert.fit(X_train ,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.918 (+/-0.046) for {'epochs': 50, 'learning_rate': 2e-05}\n",
      "0.921 (+/-0.055) for {'epochs': 50, 'learning_rate': 3e-05}\n",
      "0.918 (+/-0.046) for {'epochs': 50, 'learning_rate': 1e-05}\n",
      "0.921 (+/-0.049) for {'epochs': 75, 'learning_rate': 2e-05}\n",
      "0.918 (+/-0.046) for {'epochs': 75, 'learning_rate': 3e-05}\n",
      "0.914 (+/-0.046) for {'epochs': 75, 'learning_rate': 1e-05}\n",
      "0.921 (+/-0.037) for {'epochs': 100, 'learning_rate': 2e-05}\n",
      "0.918 (+/-0.038) for {'epochs': 100, 'learning_rate': 3e-05}\n",
      "0.918 (+/-0.038) for {'epochs': 100, 'learning_rate': 1e-05}\n",
      "\n",
      "Best score: 0.9213483146067416 with params: {'epochs': 50, 'learning_rate': 3e-05}\n"
     ]
    }
   ],
   "source": [
    "means = clf_bert.cv_results_['mean_test_score']\n",
    "stds = clf_bert.cv_results_['std_test_score']\n",
    "\n",
    "for mean, std, params in zip(means, stds, clf_bert.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "        \n",
    "# best scores\n",
    "print(\"\\nBest score:\", clf_bert.best_score_,\"with params:\", clf_bert.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a batch size\n",
    "batch_size = 5\n",
    "epochs = 50\n",
    "learning_rate = 3e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = {'control': 0, 'case': 1}\n",
    "# initialise the model use pretrained bert_2 instance and the label numbers\n",
    "model = BERT_Text_Classifier(bert_2, class_num=len(categories))\n",
    "\n",
    "# push the model to GPU\n",
    "model = model.to(device)\n",
    "\n",
    "# define the optimizer\n",
    "# optimizer = AdamW(model.parameters(),\n",
    "#                   lr = learning_rate)\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "cross_entropy  = nn.NLLLoss() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:01<00:00, 28.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 108.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.767 dev performance, p:0.150, r:0.044, f1:0.068\n",
      "current best score is 0.068\n",
      "\n",
      " Epoch 2 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 28.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 108.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.760 dev performance, p:0.143, r:0.044, f1:0.067\n",
      "\n",
      " Epoch 3 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 28.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 110.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.751 dev performance, p:0.407, r:0.162, f1:0.232\n",
      "current best score is 0.232\n",
      "\n",
      " Epoch 4 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 29.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 110.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.750 dev performance, p:0.280, r:0.103, f1:0.151\n",
      "\n",
      " Epoch 5 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 28.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 111.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.730 dev performance, p:0.541, r:0.294, f1:0.381\n",
      "current best score is 0.381\n",
      "\n",
      " Epoch 6 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 29.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 110.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.734 dev performance, p:0.300, r:0.132, f1:0.184\n",
      "\n",
      " Epoch 7 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:01<00:00, 29.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 109.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.723 dev performance, p:0.568, r:0.309, f1:0.400\n",
      "current best score is 0.400\n",
      "\n",
      " Epoch 8 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 29.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 110.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.716 dev performance, p:0.627, r:0.471, f1:0.538\n",
      "current best score is 0.538\n",
      "\n",
      " Epoch 9 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:01<00:00, 29.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 110.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.707 dev performance, p:0.638, r:0.441, f1:0.522\n",
      "\n",
      " Epoch 10 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:01<00:00, 28.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 110.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.698 dev performance, p:0.649, r:0.544, f1:0.592\n",
      "current best score is 0.592\n",
      "\n",
      " Epoch 11 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 28.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 109.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.691 dev performance, p:0.677, r:0.618, f1:0.646\n",
      "current best score is 0.646\n",
      "\n",
      " Epoch 12 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 29.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 110.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.684 dev performance, p:0.743, r:0.765, f1:0.754\n",
      "current best score is 0.754\n",
      "\n",
      " Epoch 13 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:01<00:00, 29.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 110.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.681 dev performance, p:0.743, r:0.765, f1:0.754\n",
      "\n",
      " Epoch 14 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 29.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 111.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.670 dev performance, p:0.753, r:0.853, f1:0.800\n",
      "current best score is 0.800\n",
      "\n",
      " Epoch 15 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 29.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 106.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.661 dev performance, p:0.787, r:0.868, f1:0.825\n",
      "current best score is 0.825\n",
      "\n",
      " Epoch 16 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 27.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 106.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.657 dev performance, p:0.795, r:0.971, f1:0.874\n",
      "current best score is 0.874\n",
      "\n",
      " Epoch 17 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 27.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 99.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.648 dev performance, p:0.774, r:0.956, f1:0.855\n",
      "\n",
      " Epoch 18 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 27.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 110.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.643 dev performance, p:0.774, r:0.956, f1:0.855\n",
      "\n",
      " Epoch 19 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 29.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 111.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.635 dev performance, p:0.815, r:0.971, f1:0.886\n",
      "current best score is 0.886\n",
      "\n",
      " Epoch 20 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 29.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 111.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.627 dev performance, p:0.850, r:1.000, f1:0.919\n",
      "current best score is 0.919\n",
      "\n",
      " Epoch 21 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 29.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 111.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.618 dev performance, p:0.788, r:0.985, f1:0.876\n",
      "\n",
      " Epoch 22 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 29.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 111.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.614 dev performance, p:0.810, r:1.000, f1:0.895\n",
      "\n",
      " Epoch 23 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 29.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 111.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.606 dev performance, p:0.819, r:1.000, f1:0.901\n",
      "\n",
      " Epoch 24 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 29.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 106.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.600 dev performance, p:0.810, r:1.000, f1:0.895\n",
      "\n",
      " Epoch 25 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 29.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 104.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.599 dev performance, p:0.827, r:0.985, f1:0.899\n",
      "\n",
      " Epoch 26 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 29.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 104.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.586 dev performance, p:0.848, r:0.985, f1:0.912\n",
      "\n",
      " Epoch 27 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 29.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 105.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.584 dev performance, p:0.810, r:1.000, f1:0.895\n",
      "\n",
      " Epoch 28 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 29.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 104.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.574 dev performance, p:0.880, r:0.971, f1:0.923\n",
      "current best score is 0.923\n",
      "\n",
      " Epoch 29 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 29.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 104.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.575 dev performance, p:0.850, r:1.000, f1:0.919\n",
      "\n",
      " Epoch 30 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 28.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 105.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.568 dev performance, p:0.840, r:1.000, f1:0.913\n",
      "\n",
      " Epoch 31 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 29.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 107.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.558 dev performance, p:0.840, r:1.000, f1:0.913\n",
      "\n",
      " Epoch 32 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 27.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 110.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.555 dev performance, p:0.872, r:1.000, f1:0.932\n",
      "current best score is 0.932\n",
      "\n",
      " Epoch 33 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 27.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 110.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.545 dev performance, p:0.782, r:1.000, f1:0.877\n",
      "\n",
      " Epoch 34 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 27.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 110.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.541 dev performance, p:0.883, r:1.000, f1:0.938\n",
      "current best score is 0.938\n",
      "\n",
      " Epoch 35 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 27.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 108.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.538 dev performance, p:0.850, r:1.000, f1:0.919\n",
      "\n",
      " Epoch 36 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 27.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 108.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.536 dev performance, p:0.872, r:1.000, f1:0.932\n",
      "\n",
      " Epoch 37 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 27.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 110.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.523 dev performance, p:0.895, r:1.000, f1:0.944\n",
      "current best score is 0.944\n",
      "\n",
      " Epoch 38 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 29.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 112.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.520 dev performance, p:0.872, r:1.000, f1:0.932\n",
      "\n",
      " Epoch 39 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 29.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 112.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.510 dev performance, p:0.861, r:1.000, f1:0.925\n",
      "\n",
      " Epoch 40 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 29.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 112.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.507 dev performance, p:0.810, r:1.000, f1:0.895\n",
      "\n",
      " Epoch 41 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 29.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 109.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.504 dev performance, p:0.907, r:1.000, f1:0.951\n",
      "current best score is 0.951\n",
      "\n",
      " Epoch 42 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 29.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 111.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.501 dev performance, p:0.883, r:1.000, f1:0.938\n",
      "\n",
      " Epoch 43 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 29.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 111.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.498 dev performance, p:0.872, r:1.000, f1:0.932\n",
      "\n",
      " Epoch 44 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 29.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 110.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.488 dev performance, p:0.882, r:0.985, f1:0.931\n",
      "\n",
      " Epoch 45 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:01<00:00, 29.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 111.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.489 dev performance, p:0.895, r:1.000, f1:0.944\n",
      "\n",
      " Epoch 46 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 29.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 112.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.484 dev performance, p:0.907, r:1.000, f1:0.951\n",
      "\n",
      " Epoch 47 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 29.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 111.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.474 dev performance, p:0.895, r:1.000, f1:0.944\n",
      "\n",
      " Epoch 48 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 29.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 112.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.473 dev performance, p:0.919, r:1.000, f1:0.958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current best score is 0.958\n",
      "\n",
      " Epoch 49 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:01<00:00, 29.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 112.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.468 dev performance, p:0.883, r:1.000, f1:0.938\n",
      "\n",
      " Epoch 50 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 54/54 [00:01<00:00, 29.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 112.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.466 dev performance, p:0.919, r:1.000, f1:0.958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#for each epoch\n",
    "\n",
    "best_model_state = None\n",
    "best_score = -1\n",
    "\n",
    "for epoch in range(epochs):\n",
    "     \n",
    "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs), flush=True)\n",
    "    #train model\n",
    "    train_loss, performance = train()\n",
    "    print('\\nTraining Loss: {:.3f}'.format(train_loss), \n",
    "          'dev performance, p:{precision:.3f}, r:{recall:.3f}, f1:{f1:.3f}'.format(**performance), flush=True)\n",
    "    if best_score < performance['f1']:\n",
    "        best_score = performance['f1']\n",
    "        best_model_state = copy.deepcopy(model.state_dict())\n",
    "        print('current best score is {0:.3f}'.format(best_score), flush=True)    \n",
    "\n",
    "ran = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = 'MEH_bluebert_gridsearch.pt'\n",
    "torch.save(best_model_state, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not ran:\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    model_file = 'MEH_bluebert_gridsearch.pt'\n",
    "\n",
    "    categories = {'control': 0, 'case': 1}\n",
    "    # initialise the model use pretrained bert instance and the label numbers\n",
    "    model = BERT_Text_Classifier(bert_2, class_num=len(categories))\n",
    "\n",
    "    model.load_state_dict(torch.load(model_file))\n",
    "    model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seq = test_seq.to(device)\n",
    "test_mask = test_mask.to(device)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:00<00:00, 111.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': 0.8928571428571429, 'recall': 1.0, 'f1': 0.9433962264150945}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# dataLoader for test set\n",
    "# wrap tensors\n",
    "testing_data = TensorDataset(test_seq, test_mask, test_y)\n",
    "testing_data_loader = DataLoader(testing_data, batch_size=batch_size)     \n",
    "print(evaluate(model, testing_data_loader))\n",
    "# preds = np.argmax(preds.detach().cpu(), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.47      0.64        15\n",
      "           1       0.90      1.00      0.95        75\n",
      "\n",
      "    accuracy                           0.91        90\n",
      "   macro avg       0.95      0.73      0.79        90\n",
      "weighted avg       0.92      0.91      0.90        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predicting, so gradients\n",
    "with torch.no_grad():\n",
    "    preds = model(test_seq, test_mask)\n",
    "    \n",
    "preds = np.argmax(preds.detach().cpu(), axis = 1)\n",
    "print(classification_report(test_y, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAEWCAYAAACZnQc8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAonklEQVR4nO3debwcVZn/8c/3JiQECDuEhF0ICIgsIiA7BJBFJeDCJgYGJ6PiNriB8lNUcEBFUVHHCEJYhh0kiCwxkmGVPSLbyA6BkLAa9iU8vz/OuaHS6dvdt+m+Xel833nVK13bqae66z596lT1KUUEZmbWHXo6HYCZmbWOk7qZWRdxUjcz6yJO6mZmXcRJ3cysizipm5l1kY4mdUnDJF0q6V+Szn8X5Rwo6apWxtYJki6XNK4N5e4t6XFJL0napIn1p0r6bKvjKislp0p6XtLNnY6nSNK2kv6vxvzTJB0zkDH1V3+PJ0lDJd0jaWQ742pGO/82JJ0g6fP9Xa+hpC7pAEm35qQwIyefbfof5nw+AYwAlouITzZbSEScFRG7tiCeeUjaQVJIurhi+kZ5+tQGyzla0pn1louI3SNiYpPh1vJT4IsRsURE3FElvpD0cv58n5F0tqSlWx2EpIMlzcnbeUnSQ8WDVtIaOZaXKoZ98/zTJL2Rpz0nabKk9+Yv9d5lX5X0dnH9JkLdBtgFWCUiNm/08+svSaMlnSPpaUmzJd0v6VeSVulrnYi4NiLWbXJ7Q3KimJ7fm0ckndj0Dgyc8cA1ETED5h4HIWmv4kKSfp6nH5zHK4+33mFUnv+IpJ0ryjhY0nXt2Ilq26vjp8C3JQ3pz3bqJnVJhwMnAj8iJeDVgN8Ae9VYrVGrA/+MiLdaUFa7PA18SNJyhWnjgH+2agO5ZtjOs6bVgbvrLLNRRCwBvAdYBji6TbHcmL9clgA+Dvy4ytnD0r3L5OHcwrwf53VXBp4ATslf6r1l7g48WVy/iRhXBx6JiJebWHc+kgZXmbY2cBPwJLBJRCwJbA08SPpSaaicfjoS2AzYHBgO7ADc/i7LnE8L4qz0OeCMimn/BD5Tsc1Pkd6/ohsrjqUlIuLJFsfXFvlL7D7gY/1Zr2YikbQU8APgsIi4KCJejog3I+LSiPhGXmaopBMlPZmHEyUNzfN2yLWCr0malWv5h+R53we+C+ybvz0PrawRFWpug/P4wbl296KkhyUdWJh+XWG9rSTdotSsc4ukrQrzpkr6oaTrczlXSVq+xtvwBvBHYL+8/iBgX+CsivfqF0pNHLMl3SZp2zx9N+Dbhf38eyGOYyVdD7wCvEeFUzlJv5V0YaH84yVNkaQqn1OPpKMkPZrf59MlLZU/m5eAQcDfJVUe8POJiNnAJGD9avMb+IyWknRK/qyfkHRMfs+qbesO4F5gvXpxVVn3VeA8YOP+rpvj7OvzOhQ4mfRF/pKkm6j++fW5n/l4vF6p5vgs1b8gjwauj4jDI2J63qdZEXFiRJyTy+n9+/mWpKeAU3unFfZjE0m352P5XGDRGrv9QeDiiHgykkci4vRCWaMkXah05vCwpC8X5m0u6UZJL+R9PkmFGmQ+Bg6TdD9wf562l6Rp+T1+MP8t9Fq9kb9BSauRKho3Vcy6FNhG0jJ5fDfgTuCpGvv/rknaRdJ9ObecBKgwby1Jf5X0rNIZ71nKZ7ySziBViC/Nx9E38/TzJT2Vy7tG0gYVm5wK7NmfGOvVDj9EOkgurrHMd4AtSX9cG5FqAUcV5q8ELEWqWR0K/FrSMhHxPVLt/9z87XlKrUAkLQ78Etg9IoYDWwHTqiy3LHBZXnY54GfAZZq3pn0AcAiwIjAE+HqtbQOn806t4MPAXaQaVtEtpPdgWeB/gPMlLRoRV1Ts50aFdQ4inVoOBx6tKO9rwIY5QWxLeu/GRfV+HQ7Ow46kP4AlgJMi4vVCTXWjiFirzn6S/0jGAn+rt2wfTgPeAtYGNgF2Baq2OUr6ILAOcGt/N5KPh/2BB5qMs6/P6xRSzbC3hrcF1T+/06i9n1sAD5HObo+tsv2dgQurTK+0Uo5xddKxMldOqn8k1WKXBc4nnf305W/A4ZK+IGnDYgVB6UzxUuDvpL/VMcBXJX04LzIH+E9geVJeGAN8oaL8saT9Xl/S5qS/m28ASwPbAY8Ulm30b3BD4KEqZ/OvAZeQK1ukv8/TaaP8xXMRKb8tTzor2Lq4CPBfwChSRWVV8hd6RBwEPAZ8NB9HP87rXA6MJr0Pt1NRWSRVejaiPyKizwE4EHiqzjIPAnsUxj9MOnWFdHr3KjC4MH8WsGV+fTRwZmFe5fgaQACDgcWBF0gH7bCKGA4GrsuvDwJurph/I3Bwfj0VOKow7wvAFX3s2w7A9Pz6fmBd4Jz8vnwWmFrjfXmelEjn269CHD+oMu2zhfEtgOdICX//GtuaAnyhML4u8Gbv+57fw7VrrB/A7Pz+ziGd8q1cLa46n9EI4PXi50NKvFcXPqe38nZezOv9ClBFWS9UDOvl+aeR/phfAN4GHgbe39dn1p+h4vOaezz1sc+N7Odjdbb3FrBbYfyLeb9eAn5f2Jc3gEX7OCa3I1UuVJh/A3BMH9scBBwGXJ/jf5JUUYB0rD1WsfyRwKl9lPVVUq2/eAztVBj/HfDzPtadSuN/gwcCf6uYdhpwDKmZ6kbSl8ZMYBhwHe/8rRePt97hwUI5j+T3uzj/leJnX7HdzxRjISXx6RT+ZiuWHwvcUbG9nWscE0vn93GpwrRdSF9qDR/L9WrqzwLLq3Yb2SjmrWU+mqfNLSPm/ZZ9hVST7JdI7Zv7kmpRMyRdJum9DcTTG9PKhfHiKVqj8ZxB+sPbkSpnLpK+LunefBr1AunspFazDsDjtWZGxE2k2p5ITQ19qfYZ9CbZRm0aEUuTzsx+C1wrqdapfDWrA4uQPp8X8vvwO1ItpNffImLpSGdbKwEbkGrCRcvnZXqHewvzfprjXINUYWj2omEzn1evRvaz5mdL+tuaezdHRJyU9+vEXHavpyPitT7KGAU8EfmvP6s89ueKiDkR8euI2JqUQI4F/iBpvbxPo3r3J+/Tt8nHkKR1JP0pNxXMJn1mle9XcZ9XZf727aJG/wafJ53JVtuf64AVSK0Ff4rUJFfpbxXHUuXZ6tjifOY/+ygaRWEf8/s+d1zSCKUL30/k9+hMahxTkgZJOi43Tc3mnTOZ4jrDSV82DauX1G8kfaOPrbHMk6QDotdqzN800aiXgcUK4ysVZ0bElRGxC+mP4T7g9w3E0xvTE03G1OsM0gf+54h4pTgjN498k3ShZpl8cPyLd9rb+uoKs2YXmZIOA4aS9umbNRat9hm8Raq99EtEvElqU14TeF+VRWp9Ro+TjpdiUl4yIirbCXu3NZPUBPHRJuJ8DPgK8AtJw/qzbgOf13ybqxhvZD/rdX86BdingXBrlTMDWLnYjEL67OsXGvFqRPyalDTXJ+3TwxUJcHhE7JFX+S3pb250pIu632b+96sY6+NA3ea+BtwJrFmjYnkmqamyrU0v2QzSlxWQbnAojpO+6ALYML9Hn2be96jyszyAdMPJzqRKxRq9RReWWY/UJNawmkk9Iv5Fupj5a0ljJS0maRFJu0vqbRM6GzhK0gq5zem7pDe6GdOA7SStpnSR9sjeGflbcK/clvo66bTp7Spl/BlYR+k2zMFKt8OtD/ypyZgAiIiHge1JtYJKw0lJ9GlgsKTvAksW5s8E1lA/7nCRtA7pFPPTpCalb0rauI/Fzwb+U9KakpbgnTbgft9VpHSx7xBSLfihKotMo4/PKNLV+quAEyQtqXQBdy1J2/exreWAval/Z05VETGZ9IU2vt6yFep9XpXm+fz6u599OBrYVtLPJK0Mc9ts+3PR+Ma8H1/Of5f7kK5pVSXpq0oXWoflv41xpPfiDuBm4EWli7LDci3yffm6B3m52cBL+Qy53v3TpwCHSBqT35+V+zizrinSReQHauzXL0lNFNf0t+wmXAZsIGmf/CXzZeat1Awn5aV/5c/0GxXrzyRd8you/zrprG0x5j9jhZRzLu9PkHWTTEScABxOujjwNOkb+IukCzSQEs+tpG/Uf5Aa+5v68UP+Iz03l3Ub8ybinhzHk6R25u2pcmBFxLPAR0jf3s+SamQfiYhnmompouzrovrtUFcCV5Bus3qU1O5bPBXt/WHVs5Lq3kKWD5gzgeMj4u8RcT+pZnSG8p1FFf5AOpO4htTO/Brwpcb2aq6/K90p8zzpls29I+K5yoXqfEaQ2h2HAPfksi6g0MzAO3eVvES6CPR0lVhf0Lz3FR9eI+6fkL7wqr0vfan3eVWq9vnV28+aIuKfpHbsVUjv/Yuktu4ngf/XYBlvkGr7B5P+JvYlXcjryyvACaSmj2dI7esfj4iHImIO6e9mY9Ix9AzpjG2pvO7XSTXLF0lnyOdSQ0TcTKoc/Jx0FvS/zH8G3ajfkSo21bbzXERMqWiCKvqQ5r9P/YN9LFtTziGfBI4j5ZbRpM+s1/eBTUn7exnzfxb/RaoAvyDp66Szi0dJrQj3UHFzgtKPrdbnnVzbEPX9XpiZdV7+wr4DGJPPkhYKkk4gXdj9Tb/Wc1I3M+se7tDLzKyLOKmbmXURJ3Uzsy7S6o53OmrYJl/0BQKbz/O3nNTpEKyEFh3c5+8SGtafnPPqHSe96+01wjV1M7Mu0lU1dTOzAdXWHrOb46RuZtasnqq9SneUk7qZWbPmf7xBxzmpm5k1y80vZmZdxDV1M7Mu4pq6mVkXcU3dzKyL+O4XM7Mu4uYXM7MuUsLml/J9zZiZLSjU0/hQqxhpXUnTCsPs/PjBZSVNlnR//n+ZeiE5qZuZNatFST0i/i8iNo6IjYEPkB49eDFwBDAlIkaTHlZ+RL2QnNTNzJo1aFDjQ+PGkB5j9yiwFzAxT58IjK23spO6mVmzpIYHSeMl3VoYxvdR6n7A2fn1iMJzWZ8CRtQLyRdKzcya1Y+7XyJiAjChZnHSEOBjwJFV1g9Jdftvd03dzKxZ/aipN2h34PaImJnHZ0oamTalkcCsegU4qZuZNatFF0oL9uedpheAScC4/HoccEm9ApzUzcya1cKauqTFgV2AiwqTjwN2kXQ/sHMer8lt6mZmzWphNwER8TKwXMW0Z0l3wzTMSd3MrFnuJsDMrIuUsJsAJ3Uzs2a5pm5m1kWc1M3Muoj7Uzcz6yJuUzcz6yJufjEz6yKuqZuZdQ85qZuZdQ8ndTOzLqIeJ3Uzs67hmrqZWRdxUjcz6yJO6mZm3aR8Od1J3cysWa6pm5l1kZ4e/6LUzKxruKZuZtZNypfTndTNzJpVxpp6+RqEzMwWEJIaHhooa2lJF0i6T9K9kj4kaVlJkyXdn/9fpl45TupmZk1SjxoeGvAL4IqIeC+wEXAvcAQwJSJGA1PyeE1O6mZmTWpVTV3SUsB2wCkAEfFGRLwA7AVMzItNBMbWi8lJ3cysSf1J6pLGS7q1MIwvFLUm8DRwqqQ7JJ0saXFgRETMyMs8BYyoF5MvlJqZNak/F0ojYgIwoY/Zg4FNgS9FxE2SfkFFU0tEhKSot53S1NQlnVd4fXzFvKsGPiIzs9paeKF0OjA9Im7K4xeQkvxMSSPztkYCs+oVVJqkDowuvN6lYt4KAxmImVlD1I+hhoh4Cnhc0rp50hjgHmASMC5PGwdcUi+kMjW/1DqtqHvKYWY20FrcTcCXgLMkDQEeAg4hVbzPk3Qo8CjwqXqFlCmpLyZpE9JODMuve7/jhnU0MjOzKlr546OImAZsVmXWmP6UU6ak/hTwsyqve8fNzMqlfD8oLVVS3yUi3qw2Q9KaAx3MgmT06ityxvH/Nnd8zZWX44e/vYylhi/Gv+2zFU8//xIA3ztpElded0+nwrQOu/7aazj+uGN5e87b7P3xT3Lov4+vv5LVVMZuAsqU1C+RNDYi3ihOlPR+0sWCNToS1QLg/kdnseV+xwHQ0yMevPJYJl39dw762If41ZlXc+IZUzocoXXanDlz+NGxP+B3vz+VESNGcMC+n2CHHXdirbXX7nRoC7QyJvUy3f1yO3C5pMV6J0jaAfgz8O8dimmBs+Pm6/Lw9Kd5bMbznQ7FSuSuf9zJqquuziqrrsoiQ4aw2x57MvVqf9m/W63s+6VVSpPUI+Io4GrgSklLSNoHOB0YGxGTOxvdguOTH/4A511x29zxz+23HTefeyT//b0DWXq4rzcvrGbNnMlKI1eaO77iiBHMnDmzgxF1hxb3/dISpUnqABFxDHAxcBtwHLBTRNxaa53iT2/feubugQiztBYZPIg9t9+QiybfAcDvz7+W9T96NFvsdxxPPTOb4w7fp8MRmnUX19RrkHSppEnAjqQfG70A/EzSpDy9qoiYEBGbRcRmg5ffYICiLacPb7M+0+57nFnPvQjArOde5O23g4jgDxddz2bvW73DEVqnrDhiBE/NeOcmslkzZzJiRN1uRKyOMib1Ml0o/Wkfr61Bn9pts3maXlZafkmeemY2AHvttBH3PDijr1Wty23wvg157LFHmD79cUasOIIr/nwZ//WTEzod1gKvhNdJy5PUI+J/q02XtCqwH1B1viWLLTqEnbZ4L1885uy50479yljev+4qRASPzniOLxXm2cJl8ODBHPmd7/L58Z/l7bfnMHbvj7P22qPrr2g1lfHul9Ik9SJJKwCfBPYHRpHa2a2GV157g1V2/NY80w79f6d3KBoro223255tt9u+02F0lZ4BvADaqNIkdUnDgX2AA4B1gIuANSNilY4GZmbWhxJW1MuT1EldSt4MHAVcl/sO3rvDMZmZ9amMNfXS3P0CHAkMBX4DHClprQ7HY2ZWk9T4MFBKk9Qj4sSI2JL0TD6APwKjJH1L0jqdi8zMrLoy3tJYmqQuaTWAiHgoIn4UERuSuqFcktRVgJlZqbimXtsfe19IuhAgIu6KiO9EhHsdMrPS6enpaXgYKGW6UFr8LntPx6IwM2uQ736pLfp4bWZWSv7xUW0bSZpNfnxdfk0ej4hYsnOhmZnNr4Q5vTxJPSIGdToGM7P+cE3dzKyLtDKnS3oEeBGYA7wVEZtJWhY4l/Tkt0eAT0VEzSfglOnuFzOzBUpPjxoeGrRjRGwcEZvl8SOAKRExGpiSx2vH1NyumJnZAPz4aC9gYn49ERhbbwUndTOzJvXnx0fFp7TlYXxFcQFcJem2wrwREdH7IISngLpPNnGbuplZk/pTA4+ICcCEGotsExFPSFoRmCzpvor1Q1Ld271dUzcza1IruwmIiCfy/7NIz5DYHJgpaWTalkaSerOtyUndzKxJrbpQKmnx/EwJJC0O7ArcBUwCxuXFxgGX1IvJzS9mZk1q4X3qI4CLc3mDgf+JiCsk3QKcJ+lQ4FHgU/UKclI3M2tSq5J6RDwEbFRl+rPAmP6U5aRuZtakEv6g1EndzKxZ7ibAzKyLlDCnO6mbmTVroXnwtKSvSFpSySmSbpe0azu2ZWbWKT1Sw8OAxdSmcv8tImaT7rVcBjgIOK5N2zIz64gyPqO0Xc0vvbuwB3BGRNytMl5RMDN7F8qY1tqV1G+TdBWwJnBk/qXU223alplZR5SwSb1tSf1QYGPgoYh4RdJywCFt2paZWUeU8UJpS5O6pE0rJr2njKcnZmatIMqX31pdUz+hxrwAdmrx9szMOqaEFfXWJvWI2LGV5ZmZlVkZWyLadZ/6YpKOkjQhj4+W9JF2bMvMrFPKeEtju+5TPxV4A9gqjz8BHNOmbZmZdcTC9OOjtSLix8CbABHxCpTwioKZ2bvQqodktFK7bml8Q9Iw0sVRJK0FvN6mbZmZdUQJm9TbltS/B1wBrCrpLGBr4OA2bcvMrCMGslmlUW1J6hExWdLtwJakZpevRMQz7diWmVmnlC+lt7fr3e2BbUhNMIuQno5tZtY1ynhLY1uSuqTfAGsDZ+dJ/yFp54g4rB3bMzPrhK7/8VHBTsB6EdF7oXQicHebtmVm1hGtvqtF0iDgVuCJiPiIpDWBc4DlgNuAgyLijZoxtTSidzwArFYYXzVPMzPrGpIaHhr0FeDewvjxwM8jYm3geVJniTW1NKlLulTSJGA4cK+kqZKuzkEOb+W2zMw6rUeND/VIWgXYEzg5j4vU6nFBXmQiMLZeOa1ufvlpi8szMyut/lwolTQeGF+YNCEiJhTGTwS+yTsV4OWAFyLirTw+HVi53nZa3aHX/7ayPDOzMutPi3pO4BOqzct9Y82KiNsk7fBuYmrX3S9bAr8C1gOGAIOAlyNiyXZsz8ysEwa17kLp1sDHJO0BLAosCfwCWFrS4FxbX4XUj1ZN7bpQehKwP3A/MAz4LPDrNm3LzKwjWnWhNCKOjIhVImINYD/grxFxIHA18Im82DjgknoxtSupExEPAIMiYk5EnArs1q5tmZl1wgB0vfst4HBJD5Da2E+pt0K77lN/RdIQYJqkHwMzaOMXiJlZJ7Sj75eImApMza8fAjbvV0wtjyg5KJf9ReBl0n3q+7RpW2ZmHVHGh2S0q0OvR/PL14DvA0g6F9i3Hdvr9c8ptR6Ragur516q+QM8W0iNWnrIuy5joen7pQ8fGsBtmZm13aCFPKmbmXWVru/QS9Kmfc0idb9rZtY1uj6pA7Uate9r8bbMzDqq69vUI2LHVpZnZlZmC0NN3cxsoVHCirqTuplZswaXMKs7qZuZNamEOb09vyhV8mlJ383jq0nq109dzczKrkdqeBiwmNpU7m9IPzbaP4+/iHtpNLMus9B0EwBsERGbSroDICKezx18mZl1jYXp7pc381OxA0DSCsDbbdqWmVlHtPAhGS3TrqT+S+BiYEVJx5I6eT+qTdsyM+uIEub0tvXSeJak24AxpC4CxkbEve3YlplZp6hfTykdGO16RulqwCvApcVpEfFYO7ZnZtYJC01NHbiM1J4u0kNU1wT+D9igTdszMxtwC01Sj4gNi+O598YvtGNbZmad0vUdevUlIm6XtMVAbMvMbKAMKuGTl9vVpn54YbQH2BR4sh3bMjPrlFb9UlTSosA1wFBSXr4gIr4naU3gHGA54DbgoIio+XzGdn3PDC8MQ0lt7Hu1aVtmZh3Ro8aHOl4HdoqIjYCNgd0kbQkcD/w8ItYGngcOrVdQy2vq+UdHwyPi660u28ysTFrVpB4RAbyURxfJQwA7AQfk6ROBo4Hf1iqrpTV1SYMjYg6wdSvLNTMrox7U8CBpvKRbC8P4YlmSBkmaBswCJgMPAi9ExFt5kenAyvVianVN/WZS+/k0SZOA84GXe2dGxEUt3p6ZWcf0p6YeEROACTXmzwE2lrQ06Rf5720mpnbd/bIo8Czp1KH3fvUAnNTNrGsMbsON6hHxgqSrST3dLp1bQN4CVgGeqBtTi+NZMd/5chfvJPO5sbZ4W2ZmHdWqNvXc6eGbOaEPA3YhXSS9mtR31jnAOOCSemW1OqkPApaAqh0iOKmbWVdp4cMvRgIT840mPcB5EfEnSfcA50g6BrgDOKVeQa1O6jMi4gctLtPMrJRaePfLncAmVaY/BPTrqXGtTurl+82smVmblPAHpS1P6mNaXJ6ZWWkN5LNHG9XSpB4Rz7WyPDOzMuv6pG5mtjApX0p3Ujcza1oJK+pO6mZmzVpo+1M3M+tGC8PdL2ZmCw1fKDUz6yJufjEz6yJufjEz6yKuqZuZdZHypXQndTOzpg1yTd3MrHuUMKc7qZuZNUslbIBxUjcza1IZa+plvCNnPpK+2ukYzMwq9aCGh4GLacFweKcDMDOrJDU+DJQFpfmlhCc5ZrawczcBzfNDq82sdHrKl9PLk9QlvUj15C1gsQEOx8ysrlbd/SJpVeB0YAQpD06IiF9IWhY4F1gDeAT4VEQ8X6us0rSpR8TwiFiyyjA8IgZ1Oj4zs0otbFN/C/haRKwPbAkcJml94AhgSkSMBqbk8ZpKU1OvRtLiwN7A/hGxZ6fjWVBccPYZXH7pRUiw5lqj+cZ3fsiQoUM7HZZ10GOPPswPvvONueMznpjOIeMP4xP7H9TBqBZ8raqpR8QMYEZ+/aKke4GVgb2AHfJiE4GpwLdqlVWamnovSUMk7S3pfNJOjgH+u8NhLTCemTWTP55/Fr/5w9mcfNbFzJnzNlf/5YpOh2Udttrqa3LymRdw8pkX8LuJ5zJ00UXZZocxnQ5rgdejxgdJ4yXdWhjGVytT0hrAJsBNwIic8AGeIjXP1FSamrqkXYH9gV2Bq0ntSx+MiEM6GtgCaM6cObz++usMHjyY1197jeWWX6HTIVmJ3H7LTYxaZVVWGjmq06Es8Ppz90tETAAm1FpG0hLAhcBXI2J2sRfIiAhJdW8aKU1SB64ArgW2iYiHAST9orMhLXiWX3EEnzxgHAfsvStDhy7KBzb/EJttsVWnw7IS+evkyxmz6+6dDqMrtPLmF0mLkBL6WRFxUZ48U9LIiJghaSQwq145ZWp+2RS4EfiLpMmSDgXqXiAtntKcNfHktgdZdi/Ons0N117NmRdezrmX/oXXXnuVv1zxp06HZSXx5ptvcsO1U9l+p107HUpX6JEaHmpRqpKfAtwbET8rzJoEjMuvxwGX1IupNDX1iJgGTAOOkLQVqSlmEUmXAxfnU5dq6809pXn8udcX+vvZb7/lb6w0chWWXmZZALbZfgx3/2MaO+/2kQ5HZmVw0w3Xss6667Hscst3OpSu0MKa+tbAQcA/JE3L074NHAeclyu5jwKfqldQaZJ6UUTcANwg6SvAzsC+1GmLsmTFlVbi3rvv5LXXXmXo0EW549abWGe9DTodlpXEX6+6nJ3c9NI6LcrqEXFdjdL6dUW7NM0vkj5deL01QES8HRFXAXd0LLAFzHobvJ/tdtyZz4/bl3//9D5EBHvu9YlOh2Ul8Oqrr3DbzTey7Y47dzqUrtGq5pdWUkQ5Wiwk3R4Rm1a+rjbeFze/WDWDyvhbbuu4UUsPedcHxi0P/avhnPPB9yw1IAdimZpf1MfrauNmZp1XwsxUpqQefbyuNm5m1nF+8lFt75V0J+m7b638mjz+ns6FZWZWXQl73i1VUl+v0wGYmfVHCXN6eZJ6RDxabbqkHtI961Xnm5l1ikpYVS/TLY1LSjpS0kmSdlXyJeAhGrjh3sxsoPlxdrWdATxP6irgs6RfUwkYm39tamZWKuWrp5crqb8nIjYEkHQyqdvd1SLitc6GZWbWhxJm9TIl9Td7X0TEHEnTndDNrMx8S2NtG0manV8LGJbHRepKeMnOhWZmNr8SXictT1L3c0jNbEHjpG5m1kXc/GJm1kVcUzcz6yIlzOlO6mZmTSthVndSNzNr0kA+/KJRTupmZk0qX0p3Ujcza14Js3ppOvQyM1vQqB//6pYl/UHSLEl3FaYtK2mypPvz/8vUK8dJ3cysSS3upfE0YLeKaUcAUyJiNDAlj9fkpG5m1iT1Y6gnIq4BnquYvBcwMb+eCIytV46TuplZkyT1Zxgv6dbCML6BTYyIiBn59VPAiHor+EKpmVmT+nNHY0RMACY0u62ICElRbznX1M3MmtTK5pc+zJQ0EiD/P6veCk7qZmbNan9WnwSMy6/HAZfUW8FJ3cysSS2+pfFs0uM815U0XdKhwHHALpLuB3bO4zW5Td3MrEmt7CUgIvbvY9aY/pTjpG5m1qSeEv6i1EndzKxp5cvqTupmZk0qYSeNTupmZs0qYU53Ujcza5Zr6mZmXUQlzOpO6mZmTSpfSndSNzNrWgkr6k7qZmbNauSXogPNSd3MrFnly+lO6mZmzSphTndSNzNrVk8JG9Wd1M3MmlTCnO6ud83Muolr6mZmTSpjTd1J3cysSb6l0cysi7imbmbWRZzUzcy6iJtfzMy6SBlr6r6l0cysSerHULcsaTdJ/yfpAUlHNBuTk7qZWbNalNUlDQJ+DewOrA/sL2n9ZkJy84uZWZNa2E3A5sADEfEQgKRzgL2Ae/pbUFcl9VWXHVrCFq7OkDQ+IiZ0Og4rFx8XrbXo4MavlEoaD4wvTJpQ+CxWBh4vzJsObNFMTG5+6V7j6y9iCyEfFx0SERMiYrPC0JYvVyd1M7POewJYtTC+Sp7Wb07qZmaddwswWtKakoYA+wGTmimoq9rUbR5uN7VqfFyUUES8JemLwJXAIOAPEXF3M2UpIloanJmZdY6bX8zMuoiTuplZF3FSX4BImiNpWmFYI0//qqTXJC1VWHYHSX8qjB8j6QpJQyVNzT9H7i3ngg7sjrVA4Zi4S9KlkpbO09eQ9GrF8fKZwnobSwpJu1WU99IA74K1mC+ULlhejYiNq0zfn3T1fB/g1MqZko4Ctgb2iIjXlX4Fd2BE3NrGWG1gzD0mJE0EDgOOzfMe7ON4gXTMXJf/v6LNMdoAck19ASdpLWAJ4CjSH2jl/K+R+pP4aES8OsDh2cC6kfTLxJqUvtU/CRwM7CJp0TbHZQPISX3BMqxwKn1xnrYfcA5wLbCupBGF5bcGPgfsHhGVp9VnFcr6SftDt3bKHUKNYd57m9eqaH7ZNk/fCng4Ih4EpgJ7Dmy01k5uflmwVGt+2R/YOyLelnQhqQZ2Up73ALAMsAtwYcV6bn7pDsMkTSPV0O8FJhfm9dX8sj+pIkD+/zPMf3zYAspJfQEmaUNgNDA5t5MPAR7mnaQ+EzgQmCLpuYi4uiOBWju9GhEbS1qM9MOVw4Bf9rVwrtF/HNhL0ndIncIuJ2l4RLw4IBFbW7n5ZcG2P3B0RKyRh1HAKEmr9y4QEf8kXUA9U9LGHYrT2iwiXgG+DHxNUq3K2hjgzohYNR8zq5Nq6XsPRJzWfk7qC7b9gIsrpl2cp88VEbcAhwCT8oVVmLdN/S/tD9XaLSLuAO7knQvmlW3qX87zKo+ZCwvrLCZpemE4fGCit1ZxNwFmZl3ENXUzsy7ipG5m1kWc1M3MuoiTuplZF3FSNzPrIk7q9q5V9BR4fv4hTLNlnSbpE/n1yZLWr7HsDpK2amIbj0havtHpfZRxsKST6i/ZXPlmzXJSt1Z4NSI2joj3AW+Q+puZq86PYfoUEZ+NiHtqLLIDqR8TM8uc1K3VrgXWzrXoayVNAu6RNEjSTyTdIulOSf8BqcdASSfl/t3/AqzYW1Du932z/Ho3SbdL+rukKbkv+c8B/9nbWZWkFSRdmLdxi6St87rLSbpK0t2STib9NL4hkjaXdKOkOyTdIGndwuxVc4z3S/peYZ1PS7o5x/W7/NP8YpmLS7os78tdkvbt75ts1hf3/WItk2vku/NO/9ybAu+LiIcljQf+FREflDQUuF7SVcAmwLrA+sAI4B7gDxXlrgD8Htgul7VsRDwn6b+BlyLip3m5/wF+HhHXSVqN1BfKesD3gOsi4geS9gQO7cdu3Qdsmx8MvDPwI1LfKQCbA+8DXgFukXQZ8DKwL7B1RLwp6Tek/ndOL5S5G/BkROyZ414KsxZxUrdW6O0pEFJN/RRSs8jNEfFwnr4r8P7e9nJgKVJnZNsBZ0fEHOBJSX+tUv6WwDW9ZUXEc33EsTOwfu7cDGBJSUvkbeyT171M0vP92LelgImSRgMBLFKYNzkingWQdBGwDfAW8AFSkgcYBsyqKPMfwAmSjgf+FBHX9iMes5qc1K0V5usSOCe0l4uTgC9FxJUVy+3Rwjh6gC0j4rUqsTTrh8DVEbF3bvKZWphX2cdGkPZzYkQc2VeBEfFPSZsCewDHSJoSET94N0Ga9XKbug2UK4HPS1oEQNI6khYHrgH2zW3uI4Edq6z7N2A7SWvmdZfN018EhheWuwr4Uu9IoVfKa4AD8rTdSX3MN2op4In8+uCKebtIWlbSMGAscD0wBfiEpBV7Y1Wh18w8bRTwSkScCfyE1Exl1hKuqdtAORlYA7hdqer8NCkRXgzsRGpLf4z0SLZ5RMTTuU3+Ikk9pOaMXYBLgQsk7UVK5l8Gfi3pTtKxfQ3pYur3gbMl3Q3ckLfTlzslvZ1fnwf8mNT8chRwWcWyN5N6OFwFOLP3oSN52atyrG+S+jh/tLDehsBP8nbeBD5fIx6zfnEvjWZmXcTNL2ZmXcRJ3cysizipm5l1ESd1M7Mu4qRuZtZFnNTNzLqIk7qZWRf5/2SO578r3rP6AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_bert = confusion_matrix(test_y, preds, labels=[1,0])\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cm_bert, annot=True, ax = ax, cmap='Blues', fmt=\"d\")\n",
    "\n",
    "ax.set_title('Confusion Matrix of BlueBERT after Grid Search (MEH data)')\n",
    "\n",
    "ax.set_xlabel('Predicted Labels')\n",
    "ax.set_ylabel('True Labels')\n",
    "\n",
    "ax.xaxis.set_ticklabels(['FAKE', 'REAL'])\n",
    "ax.yaxis.set_ticklabels(['FAKE', 'REAL'])\n",
    "plt.savefig('Confusion_matrix_BlueBERT(grid search)_meh')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
